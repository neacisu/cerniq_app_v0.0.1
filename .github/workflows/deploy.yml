# =============================================================================
# CERNIQ.APP ‚Äî CD Pipeline for Deployments (Refactored v2.0)
# =============================================================================
# Workflow: deploy.yml
# Trigger:
#   - Push to any branch except main ‚Üí Staging
#   - Push to main ‚Üí Production
#   - Manual dispatch
# 
# Features:
#   - Full configuration sync with correct server paths
#   - Automated OpenBao initialization and setup
#   - Automated firewall configuration
#   - AppRole credentials generation
#   - Initial secrets population
#   - Health verification
#
# Server structure:
#   /opt/cerniq/
#   ‚îú‚îÄ‚îÄ docker-compose.yml
#   ‚îú‚îÄ‚îÄ docker-compose.prod.yml  (production only)
#   ‚îú‚îÄ‚îÄ config/
#   ‚îÇ   ‚îú‚îÄ‚îÄ postgres/
#   ‚îÇ   ‚îî‚îÄ‚îÄ openbao/
#   ‚îú‚îÄ‚îÄ scripts/
#   ‚îî‚îÄ‚îÄ secrets/
#
# Reference: ADR-0107 CI/CD Pipeline Strategy
# Created: 2026-02-01
# Updated: 2026-02-05 - Complete refactor for automated deployments
# =============================================================================

name: CD Pipeline

on:
  push:
    branches:
      - "**"
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        type: choice
        options:
          - staging
          - production
      version:
        description: 'Version to deploy (e.g., v1.0.0)'
        required: true
        type: string

concurrency:
  group: deploy-${{ github.ref }}
  cancel-in-progress: false

env:
  REGISTRY: ghcr.io
  IMAGE_PREFIX: ${{ github.repository_owner }}/cerniq

jobs:
  # ===========================================================================
  # JOB 1: Determine Environment and Version
  # ===========================================================================
  setup:
    name: üîß Setup Deployment
    runs-on: self-hosted
    permissions:
      contents: write
    outputs:
      environment: ${{ steps.determine.outputs.environment }}
      version: ${{ steps.determine.outputs.version }}
      sha: ${{ steps.determine.outputs.sha }}
      should_tag: ${{ steps.determine.outputs.should_tag }}

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: üîß Determine deployment parameters
        id: determine
        run: |
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "environment=${{ inputs.environment }}" >> $GITHUB_OUTPUT
            echo "version=${{ inputs.version }}" >> $GITHUB_OUTPUT
            echo "should_tag=false" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref_type }}" == "tag" ]]; then
            TAG="${{ github.ref_name }}"
            echo "version=${TAG}" >> $GITHUB_OUTPUT
            echo "should_tag=false" >> $GITHUB_OUTPUT
            if [[ "$TAG" =~ ^v[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
              echo "environment=production" >> $GITHUB_OUTPUT
            else
              echo "environment=staging" >> $GITHUB_OUTPUT
            fi
          else
            BRANCH="${{ github.ref_name }}"
            if [[ "$BRANCH" == "main" ]]; then
              echo "environment=production" >> $GITHUB_OUTPUT
              echo "should_tag=true" >> $GITHUB_OUTPUT
              LATEST_TAG=$(git tag -l "v0.0.*" --sort=-v:refname | head -n1)
              if [[ -z "$LATEST_TAG" ]]; then
                NEW_VERSION="v0.0.1"
              else
                PATCH=$(echo "$LATEST_TAG" | sed 's/v0\.0\.//')
                NEW_PATCH=$((PATCH + 1))
                NEW_VERSION="v0.0.${NEW_PATCH}"
              fi
              echo "version=${NEW_VERSION}" >> $GITHUB_OUTPUT
            else
              echo "environment=staging" >> $GITHUB_OUTPUT
              echo "should_tag=false" >> $GITHUB_OUTPUT
              SHORT_SHA="${{ github.sha }}"
              SHORT_SHA="${SHORT_SHA:0:7}"
              SAFE_BRANCH=$(echo "$BRANCH" | sed 's/[^a-zA-Z0-9]/-/g' | cut -c1-20)
              echo "version=${SAFE_BRANCH}-${SHORT_SHA}" >> $GITHUB_OUTPUT
            fi
          fi
          echo "sha=${{ github.sha }}" >> $GITHUB_OUTPUT

      - name: üè∑Ô∏è Create Git Tag (Production Auto-Version)
        if: steps.determine.outputs.should_tag == 'true'
        run: |
          VERSION="${{ steps.determine.outputs.version }}"
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git tag -a "$VERSION" -m "Release $VERSION (auto-generated)"
          git push origin "$VERSION"
          echo "‚úÖ Created tag: $VERSION"

      - name: üìã Display deployment info
        run: |
          echo "üéØ Environment: ${{ steps.determine.outputs.environment }}"
          echo "üè∑Ô∏è Version: ${{ steps.determine.outputs.version }}"
          echo "üìù SHA: ${{ steps.determine.outputs.sha }}"

  # ===========================================================================
  # JOB 2: Build and Push Docker Images
  # ===========================================================================
  build-push:
    name: üê≥ Build & Push Images
    runs-on: self-hosted
    needs: setup
    permissions:
      contents: read
      packages: write

    strategy:
      matrix:
        app:
          - name: api
            context: ./apps/api
          - name: web
            context: ./apps/web
          - name: web-admin
            context: ./apps/web-admin

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üê≥ Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: üîê Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: üìã Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/${{ matrix.app.name }}
          tags: |
            type=semver,pattern={{version}},value=${{ needs.setup.outputs.version }}
            type=sha,prefix=sha-

      - name: üèóÔ∏è Build and push
        uses: docker/build-push-action@v6.19.2
        with:
          context: ${{ matrix.app.context }}
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            VERSION=${{ needs.setup.outputs.version }}
            BUILD_SHA=${{ needs.setup.outputs.sha }}

      - name: üîí Scan image for vulnerabilities
        uses: aquasecurity/trivy-action@0.34.0
        with:
          image-ref: '${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/${{ matrix.app.name }}:${{ needs.setup.outputs.version }}'
          format: 'table'
          exit-code: '1'
          severity: 'CRITICAL,HIGH'
          ignore-unfixed: true

  # ===========================================================================
  # JOB 3: Deploy to Staging
  # ===========================================================================
  deploy-staging:
    name: üöÄ Deploy to Staging
    runs-on: self-hosted
    needs: [setup, build-push]
    if: needs.setup.outputs.environment == 'staging'
    environment:
      name: staging
      url: https://staging.cerniq.app

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üîß Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.STAGING_SSH_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H ${{ secrets.STAGING_HOST }} >> ~/.ssh/known_hosts 2>/dev/null

      - name: üß∞ Ensure jq on staging host
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }} << 'ENDSSH'
            if ! command -v jq >/dev/null 2>&1; then
              sudo apt-get update
              sudo apt-get install -y jq
            fi
          ENDSSH

      # =========================================================================
      # STEP 1: Sync ALL configuration files with correct structure
      # =========================================================================
      - name: üì¶ Sync ALL configuration files
        run: |
          SSH_CMD="ssh -i ~/.ssh/deploy_key ${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }}"
          SCP_CMD="scp -i ~/.ssh/deploy_key"
          HOST="${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }}"
          
          echo "üìÅ Creating COMPLETE server directory structure..."
          $SSH_CMD << 'ENDSSH'
            sudo mkdir -p /opt/cerniq/{config/{openbao/{policies,templates},vector,otel,fail2ban,cron,logrotate,docker},scripts,secrets,backups}
            sudo chown -R $(whoami):$(whoami) /opt/cerniq
          ENDSSH
          
          echo "üìÑ Syncing docker-compose files..."
          $SCP_CMD infra/docker/docker-compose.yml ${HOST}:/opt/cerniq/
          $SCP_CMD infra/docker/docker-compose.prod.yml ${HOST}:/opt/cerniq/
          $SCP_CMD infra/config/vector/vector.toml ${HOST}:/opt/cerniq/config/vector.toml 2>/dev/null || true
          $SCP_CMD infra/config/otel/otel-collector.yaml ${HOST}:/opt/cerniq/config/otel-collector.yaml 2>/dev/null || true
          
          echo "üìÑ Syncing OpenBao config (CORRECT PATH)..."
          $SCP_CMD infra/config/openbao/*.hcl ${HOST}:/opt/cerniq/config/openbao/
          $SCP_CMD infra/config/openbao/policies/*.hcl ${HOST}:/opt/cerniq/config/openbao/policies/
          $SCP_CMD infra/config/openbao/templates/*.tpl ${HOST}:/opt/cerniq/config/openbao/templates/
          
          echo "üìÑ Syncing security configs (fail2ban, cron, logrotate)..."
          $SCP_CMD infra/config/fail2ban/jail.local ${HOST}:/opt/cerniq/config/fail2ban/
          $SCP_CMD infra/config/cron/cerniq-backup ${HOST}:/opt/cerniq/config/cron/
          $SCP_CMD infra/config/logrotate/cerniq-backup ${HOST}:/opt/cerniq/config/logrotate/
          $SCP_CMD infra/config/docker/daemon.json ${HOST}:/opt/cerniq/config/docker/ 2>/dev/null || true
          
          echo "üìÑ Syncing ALL scripts..."
          $SCP_CMD infra/scripts/*.sh ${HOST}:/opt/cerniq/scripts/
          $SSH_CMD "chmod +x /opt/cerniq/scripts/*.sh"
          
          echo "‚úÖ COMPLETE configuration sync done"

      - name: üîÅ Sync orchestrator Traefik route
        continue-on-error: true
        run: |
          KEY_PATH="${HOME}/.ssh/id_ed25519_production"
          if [[ ! -f "${KEY_PATH}" ]]; then
            echo "Orchestrator SSH key not found at ${KEY_PATH}, skipping orchestrator sync"
            exit 0
          fi
          mkdir -p ~/.ssh
          ORCH_HOST="77.42.76.185"
          ORCH_USER="root"
          ssh-keyscan -H "$ORCH_HOST" >> ~/.ssh/known_hosts 2>/dev/null || true
          scp -i "${KEY_PATH}" infra/config/traefik-orchestrator/cerniq.yml "${ORCH_USER}@${ORCH_HOST}:/opt/traefik/dynamic/cerniq.yml"
          ssh -i "${KEY_PATH}" "${ORCH_USER}@${ORCH_HOST}" << 'ENDSSH'
            set -euo pipefail
            test -f /opt/traefik/dynamic_conf.yml
            python3 -c "from pathlib import Path; import yaml; b=Path('/opt/traefik/dynamic_conf.yml'); a=Path('/opt/traefik/dynamic/cerniq.yml'); base=yaml.safe_load(b.read_text()) or {}; add=yaml.safe_load(a.read_text()) or {}; bh=base.setdefault('http',{}); ah=add.get('http',{}) or {}; [bh.setdefault(s,{}).update((ah.get(s,{}) or {})) for s in ('middlewares','routers','services')]; b.write_text(yaml.safe_dump(base, sort_keys=False))"
            docker restart traefik >/dev/null
          ENDSSH

      # =========================================================================
      # STEP 2: Save current version for rollback
      # =========================================================================
      - name: üíæ Save current version for rollback
        continue-on-error: true
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }} << 'ENDSSH'
            cd /opt/cerniq
            
            # Save current deployed version for potential rollback
            if docker ps --format '{{.Image}}' | grep -q "ghcr.io"; then
              docker ps --format '{{.Image}}' | grep "ghcr.io" | head -1 | sed 's/:/ /' | awk '{print $2}' > /opt/cerniq/.previous_deploy
              echo "üíæ Saved previous version: $(cat /opt/cerniq/.previous_deploy 2>/dev/null || echo 'none')"
            else
              echo "‚ÑπÔ∏è No previous ghcr.io images found (first deployment)"
            fi
          ENDSSH

      # =========================================================================
      # STEP 3: Deploy Docker services
      # =========================================================================
      - name: üöÄ Deploy Docker services
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }} << 'ENDSSH'
            cd /opt/cerniq
            
            # Ensure Docker networks exist
            docker network create --driver bridge --subnet=172.29.10.0/24 cerniq_public 2>/dev/null || true
            docker network create --driver bridge --subnet=172.29.20.0/24 cerniq_backend 2>/dev/null || true
            docker network create --driver bridge --subnet=172.29.30.0/24 cerniq_data 2>/dev/null || true
            
            # Pull and deploy with production overlay
            echo "üê≥ Pulling images..."
            docker compose -f docker-compose.yml -f docker-compose.prod.yml pull || true
            
            echo "üöÄ Starting services..."
            docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d --force-recreate --remove-orphans
            
            echo "‚è≥ Waiting for services to start..."
            sleep 15
            
            # Verify core services
            echo "üìä Service status:"
            docker ps --format 'table {{.Names}}\t{{.Status}}' | grep cerniq || true
          ENDSSH

      # =========================================================================
      # STEP 4: Initialize OpenBao (if needed)
      # =========================================================================
      - name: üîê Initialize OpenBao
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }} << 'ENDSSH'
            cd /opt/cerniq
            echo "‚úÖ Skipped: OpenBao server is external on orchestrator (s3cr3ts.neanelu.ro)"
          ENDSSH

      # =========================================================================
      # STEP 6: Start OpenBao agents
      # =========================================================================
      - name: ü§ñ Start OpenBao Agents
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }} << 'ENDSSH'
            cd /opt/cerniq
            
            # tmpfs runtime secrets (avoid secrets persisted on disk)
            sudo mkdir -p /run/cerniq/runtime-secrets/{api,workers,infra}
            sudo chown -R $(whoami):$(whoami) /run/cerniq/runtime-secrets
            sudo chmod 700 /run/cerniq/runtime-secrets /run/cerniq/runtime-secrets/* || true
            
            # Check prerequisites
            if [ ! -f /opt/cerniq/secrets/api_role_id ]; then
              echo "‚ö†Ô∏è AppRole credentials not found, skipping agents"
              exit 0
            fi
            
            echo "ü§ñ Starting OpenBao agents..."
            docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d openbao-agent-api openbao-agent-workers openbao-agent-infra
            
            echo "‚è≥ Waiting for agents to render secrets..."
            sleep 10
            
            # Verify secrets rendered
            if docker exec cerniq-openbao-agent-api test -f /secrets/api.env 2>/dev/null; then
              echo "‚úÖ API secrets rendered successfully"
            else
              echo "‚ö†Ô∏è API secrets not yet rendered"
              docker logs cerniq-openbao-agent-api --tail 10 2>&1 || true
            fi
          ENDSSH

      # =========================================================================
      # STEP 7: Configure firewall
      # =========================================================================
      - name: üî• Configure Firewall
        continue-on-error: true
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }} << 'ENDSSH'
            cd /opt/cerniq
            
            # Check if UFW is active
            if sudo ufw status | grep -q "Status: active"; then
              echo "‚úÖ UFW already active"
            else
              echo "üî• Configuring firewall..."
              if [ -f /opt/cerniq/scripts/setup-firewall.sh ]; then
                sudo /opt/cerniq/scripts/setup-firewall.sh || echo "‚ö†Ô∏è Firewall setup had issues"
              else
                # Basic firewall setup
                sudo ufw --force reset
                sudo ufw default deny incoming
                sudo ufw default allow outgoing
                sudo ufw allow ssh
                sudo ufw allow 80/tcp
                sudo ufw allow 443/tcp
                sudo ufw --force enable
                echo "‚úÖ Basic firewall configured"
              fi
            fi
            
            sudo ufw status verbose | head -10
          ENDSSH

      # =========================================================================
      # STEP 8: Install system configurations (fail2ban, cron)
      # =========================================================================
      - name: üîß Install system configurations
        continue-on-error: true
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }} << 'ENDSSH'
            cd /opt/cerniq
            
            echo "üìã Installing fail2ban configuration..."
            if [ -f /opt/cerniq/config/fail2ban/jail.local ]; then
              sudo cp /opt/cerniq/config/fail2ban/jail.local /etc/fail2ban/jail.local
              sudo systemctl enable fail2ban 2>/dev/null || true
              sudo systemctl restart fail2ban 2>/dev/null || true
              echo "‚úÖ fail2ban configured"
            fi
            
            echo "üìã Installing backup cron job..."
            if [ -f /opt/cerniq/config/cron/cerniq-backup ]; then
              sudo cp /opt/cerniq/config/cron/cerniq-backup /etc/cron.d/cerniq-backup
              sudo chmod 644 /etc/cron.d/cerniq-backup
              sudo systemctl reload cron 2>/dev/null || true
              echo "‚úÖ Backup cron installed"
            fi
            
            echo "üìã Installing logrotate configuration..."
            if [ -f /opt/cerniq/config/logrotate/cerniq-backup ]; then
              sudo cp /opt/cerniq/config/logrotate/cerniq-backup /etc/logrotate.d/cerniq-backup
              echo "‚úÖ Logrotate configured"
            fi
          ENDSSH

      # =========================================================================
      # STEP 9: Health Check and verification (SMOKE TESTS)
      # =========================================================================
      - name: üß™ Verify Staging Deployment (Smoke Tests)
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }} << 'ENDSSH'
            echo "========================================"
            echo "  STAGING DEPLOYMENT SMOKE TESTS"
            echo "========================================"
            
            cd /opt/cerniq
            FAILED=0
            
            echo ""
            echo "üìä Container Status"
            docker ps --format 'table {{.Names}}\t{{.Status}}' | grep cerniq | sort
            
            echo ""
            echo "üîç Core Services Health Checks"
            
            # External PostgreSQL reachability (CT107)
            echo -n "  PostgreSQL: "
            if docker run --rm --network host postgres:18 pg_isready -h 10.0.1.107 -p 5432 >/dev/null 2>&1; then
              echo "‚úÖ HEALTHY"
            else
              echo "‚ùå FAILED"
              FAILED=1
            fi
            
            # PgBouncer + OpenBao dynamic creds (end-to-end)
            echo -n "  PgBouncer:  "
            if docker run --rm --network cerniq_backend \
              --env-file /run/cerniq/runtime-secrets/api/api.env \
              postgres:18 sh -c 'psql "$DATABASE_URL" -Atqc "SELECT 1"' >/dev/null 2>&1; then
              echo "‚úÖ HEALTHY"
            else
              echo "‚ö†Ô∏è NOT READY (may be initializing)"
            fi
            
            # Redis health
            echo -n "  Redis:      "
            if docker run --rm --network host \
              --env-file /run/cerniq/runtime-secrets/api/api.env \
              redis:8-alpine sh -c 'redis-cli -u "$REDIS_URL" PING' 2>/dev/null | grep -q PONG; then
              echo "‚úÖ HEALTHY"
            else
              echo "‚ùå FAILED"
              FAILED=1
            fi
            
            # Ingress health via orchestrator Traefik
            echo -n "  Ingress:    "
            if curl -skf https://staging.cerniq.app >/dev/null 2>&1; then
              echo "‚úÖ HEALTHY"
            else
              echo "‚ùå FAILED"
              FAILED=1
            fi
            
            # Vector health
            echo -n "  Vector:     "
            if docker inspect -f '{{.State.Running}}' cerniq-vector 2>/dev/null | grep -q true; then
              echo "‚úÖ HEALTHY"
            else
              echo "‚ùå FAILED"
              FAILED=1
            fi

            # OpenBao agents health (remote OpenBao on orchestrator)
            echo -n "  OpenBao:    "
            if docker inspect -f '{{.State.Health.Status}}' cerniq-openbao-agent-api 2>/dev/null | grep -q healthy && \
               docker inspect -f '{{.State.Health.Status}}' cerniq-openbao-agent-workers 2>/dev/null | grep -q healthy && \
               docker inspect -f '{{.State.Health.Status}}' cerniq-openbao-agent-infra 2>/dev/null | grep -q healthy; then
              echo "‚úÖ HEALTHY (agents)"
            else
              echo "‚ùå FAILED (agents)"
              FAILED=1
            fi
            
            echo ""
            echo "üîê Security Services"
            
            # fail2ban
            echo -n "  fail2ban:   "
            if sudo systemctl is-active fail2ban >/dev/null 2>&1; then
              echo "‚úÖ ACTIVE"
            else
              echo "‚ö†Ô∏è INACTIVE"
            fi
            
            # UFW
            echo -n "  UFW:        "
            if sudo ufw status | grep -q "Status: active"; then
              echo "‚úÖ ACTIVE"
            else
              echo "‚ö†Ô∏è INACTIVE"
            fi
            
            echo ""
            echo "========================================"
            if [ $FAILED -eq 0 ]; then
              echo "‚úÖ ALL SMOKE TESTS PASSED"
              echo "Staging deployment complete - version ${{ needs.setup.outputs.version }}"
            else
              echo "‚ùå SOME SMOKE TESTS FAILED"
              echo "Review the failures above and check container logs"
              exit 1
            fi
            echo "========================================"
          ENDSSH

  # ===========================================================================
  # JOB 4: Deploy to Production
  # ===========================================================================
  deploy-production:
    name: üöÄ Deploy to Production
    runs-on: self-hosted
    needs: [setup, build-push]
    if: needs.setup.outputs.environment == 'production'
    environment:
      name: production
      url: https://cerniq.app

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üîß Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.PRODUCTION_SSH_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H ${{ secrets.PRODUCTION_HOST }} >> ~/.ssh/known_hosts 2>/dev/null

      - name: üß∞ Ensure jq on production host
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }} << 'ENDSSH'
            if ! command -v jq >/dev/null 2>&1; then
              sudo apt-get update
              sudo apt-get install -y jq
            fi
          ENDSSH

      - name: üîÑ Create database backup
        continue-on-error: true
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }} << 'ENDSSH'
            if [ -f /opt/cerniq/scripts/backup-pre-deploy.sh ]; then
              /opt/cerniq/scripts/backup-pre-deploy.sh
            fi
          ENDSSH

      # =========================================================================
      # STEP 1: Sync ALL configuration files
      # =========================================================================
      - name: üì¶ Sync ALL configuration files
        run: |
          SSH_CMD="ssh -i ~/.ssh/deploy_key ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }}"
          SCP_CMD="scp -i ~/.ssh/deploy_key"
          HOST="${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }}"
          
          echo "üìÅ Creating COMPLETE server directory structure..."
          $SSH_CMD << 'ENDSSH'
            sudo mkdir -p /opt/cerniq/{config/{openbao/{policies,templates},vector,otel,fail2ban,cron,logrotate,docker},scripts,secrets,backups}
            sudo chown -R $(whoami):$(whoami) /opt/cerniq
          ENDSSH
          
          echo "üìÑ Syncing docker-compose files..."
          $SCP_CMD infra/docker/docker-compose.yml ${HOST}:/opt/cerniq/
          $SCP_CMD infra/docker/docker-compose.prod.yml ${HOST}:/opt/cerniq/
          $SCP_CMD infra/config/vector/vector.toml ${HOST}:/opt/cerniq/config/vector.toml 2>/dev/null || true
          $SCP_CMD infra/config/otel/otel-collector.yaml ${HOST}:/opt/cerniq/config/otel-collector.yaml 2>/dev/null || true
          
          echo "üìÑ Syncing OpenBao config (CORRECT PATH)..."
          $SCP_CMD infra/config/openbao/*.hcl ${HOST}:/opt/cerniq/config/openbao/
          $SCP_CMD infra/config/openbao/policies/*.hcl ${HOST}:/opt/cerniq/config/openbao/policies/
          $SCP_CMD infra/config/openbao/templates/*.tpl ${HOST}:/opt/cerniq/config/openbao/templates/
          
          echo "üìÑ Syncing security configs (fail2ban, cron, logrotate)..."
          $SCP_CMD infra/config/fail2ban/jail.local ${HOST}:/opt/cerniq/config/fail2ban/
          $SCP_CMD infra/config/cron/cerniq-backup ${HOST}:/opt/cerniq/config/cron/
          $SCP_CMD infra/config/logrotate/cerniq-backup ${HOST}:/opt/cerniq/config/logrotate/
          $SCP_CMD infra/config/docker/daemon.json ${HOST}:/opt/cerniq/config/docker/ 2>/dev/null || true
          
          echo "üìÑ Syncing ALL scripts..."
          $SCP_CMD infra/scripts/*.sh ${HOST}:/opt/cerniq/scripts/
          $SSH_CMD "chmod +x /opt/cerniq/scripts/*.sh"
          
          echo "‚úÖ COMPLETE configuration sync done"

      - name: üîÅ Sync orchestrator Traefik route
        continue-on-error: true
        run: |
          KEY_PATH="${HOME}/.ssh/id_ed25519_production"
          if [[ ! -f "${KEY_PATH}" ]]; then
            echo "Orchestrator SSH key not found at ${KEY_PATH}, skipping orchestrator sync"
            exit 0
          fi
          mkdir -p ~/.ssh
          ORCH_HOST="77.42.76.185"
          ORCH_USER="root"
          ssh-keyscan -H "$ORCH_HOST" >> ~/.ssh/known_hosts 2>/dev/null || true
          scp -i "${KEY_PATH}" infra/config/traefik-orchestrator/cerniq.yml "${ORCH_USER}@${ORCH_HOST}:/opt/traefik/dynamic/cerniq.yml"
          ssh -i "${KEY_PATH}" "${ORCH_USER}@${ORCH_HOST}" << 'ENDSSH'
            set -euo pipefail
            test -f /opt/traefik/dynamic_conf.yml
            python3 -c "from pathlib import Path; import yaml; b=Path('/opt/traefik/dynamic_conf.yml'); a=Path('/opt/traefik/dynamic/cerniq.yml'); base=yaml.safe_load(b.read_text()) or {}; add=yaml.safe_load(a.read_text()) or {}; bh=base.setdefault('http',{}); ah=add.get('http',{}) or {}; [bh.setdefault(s,{}).update((ah.get(s,{}) or {})) for s in ('middlewares','routers','services')]; b.write_text(yaml.safe_dump(base, sort_keys=False))"
            docker restart traefik >/dev/null
          ENDSSH

      # =========================================================================
      # STEP 2: Save current version for rollback
      # =========================================================================
      - name: üíæ Save current version for rollback
        continue-on-error: true
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }} << 'ENDSSH'
            cd /opt/cerniq
            
            # Save current deployed version for potential rollback
            if docker ps --format '{{.Image}}' | grep -q "ghcr.io"; then
              docker ps --format '{{.Image}}' | grep "ghcr.io" | head -1 | sed 's/:/ /' | awk '{print $2}' > /opt/cerniq/.previous_deploy
              echo "üíæ Saved previous version: $(cat /opt/cerniq/.previous_deploy 2>/dev/null || echo 'none')"
            else
              echo "‚ÑπÔ∏è No previous ghcr.io images found (first deployment)"
            fi
          ENDSSH

      # =========================================================================
      # STEP 3: Deploy Docker services
      # =========================================================================
      - name: üöÄ Deploy Docker services
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }} << 'ENDSSH'
            cd /opt/cerniq
            
            # Ensure Docker networks exist
            docker network create --driver bridge --subnet=172.29.10.0/24 cerniq_public 2>/dev/null || true
            docker network create --driver bridge --subnet=172.29.20.0/24 cerniq_backend 2>/dev/null || true
            docker network create --driver bridge --subnet=172.29.30.0/24 cerniq_data 2>/dev/null || true
            
            # Deploy with production overlay
            echo "üê≥ Pulling images..."
            docker compose -f docker-compose.yml -f docker-compose.prod.yml pull || true
            
            echo "üöÄ Starting services..."
            docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d --remove-orphans
            
            echo "‚è≥ Waiting for services to start..."
            sleep 20
            
            echo "üìä Service status:"
            docker ps --format 'table {{.Names}}\t{{.Status}}' | grep cerniq || true
          ENDSSH

      # =========================================================================
      # STEP 4: Initialize OpenBao (if needed) - NO AUTO-UNSEAL IN PRODUCTION
      # =========================================================================
      - name: üîê Initialize OpenBao (Production)
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }} << 'ENDSSH'
            cd /opt/cerniq
            echo "‚úÖ Skipped: OpenBao server is external on orchestrator (s3cr3ts.neanelu.ro)"
          ENDSSH

      # =========================================================================
      # STEP 6: Start agents (external OpenBao, if configured)
      # =========================================================================
      - name: ü§ñ Start OpenBao Agents
        continue-on-error: true
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }} << 'ENDSSH'
            cd /opt/cerniq
            
            # tmpfs runtime secrets (avoid secrets persisted on disk)
            sudo mkdir -p /run/cerniq/runtime-secrets/{api,workers,infra}
            sudo chown -R $(whoami):$(whoami) /run/cerniq/runtime-secrets
            sudo chmod 700 /run/cerniq/runtime-secrets /run/cerniq/runtime-secrets/* || true
            
            if [ ! -f /opt/cerniq/secrets/api_role_id ]; then
              echo "‚ö†Ô∏è AppRole credentials not found, skipping agents"
              exit 0
            fi
            
            docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d openbao-agent-api openbao-agent-workers openbao-agent-infra
            
            sleep 10
            
            if docker exec cerniq-openbao-agent-api test -f /secrets/api.env 2>/dev/null; then
              echo "‚úÖ API secrets rendered"
            else
              echo "‚ö†Ô∏è API secrets not rendered yet"
            fi
          ENDSSH

      # =========================================================================
      # STEP 7: Configure firewall
      # =========================================================================
      - name: üî• Configure Firewall
        continue-on-error: true
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }} << 'ENDSSH'
            cd /opt/cerniq
            
            if sudo ufw status | grep -q "Status: active"; then
              echo "‚úÖ UFW already active"
            else
              echo "üî• Configuring production firewall..."
              if [ -f /opt/cerniq/scripts/setup-firewall.sh ]; then
                sudo CERNIQ_UFW_AUTO_APPROVE=true /opt/cerniq/scripts/setup-firewall.sh
              else
                sudo ufw --force reset
                sudo ufw default deny incoming
                sudo ufw default allow outgoing
                sudo ufw allow ssh
                sudo ufw allow 80/tcp
                sudo ufw allow 443/tcp
                sudo ufw --force enable
              fi
            fi
            
            sudo ufw status verbose | head -10
          ENDSSH

      # =========================================================================
      # STEP 8: Install system configurations (fail2ban, cron)
      # =========================================================================
      - name: üîß Install system configurations
        continue-on-error: true
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }} << 'ENDSSH'
            cd /opt/cerniq
            
            echo "üìã Installing fail2ban configuration..."
            if [ -f /opt/cerniq/config/fail2ban/jail.local ]; then
              sudo cp /opt/cerniq/config/fail2ban/jail.local /etc/fail2ban/jail.local
              sudo systemctl enable fail2ban 2>/dev/null || true
              sudo systemctl restart fail2ban 2>/dev/null || true
              echo "‚úÖ fail2ban configured"
            fi
            
            echo "üìã Installing backup cron job..."
            if [ -f /opt/cerniq/config/cron/cerniq-backup ]; then
              sudo cp /opt/cerniq/config/cron/cerniq-backup /etc/cron.d/cerniq-backup
              sudo chmod 644 /etc/cron.d/cerniq-backup
              sudo systemctl reload cron 2>/dev/null || true
              echo "‚úÖ Backup cron installed"
            fi
            
            echo "üìã Installing logrotate configuration..."
            if [ -f /opt/cerniq/config/logrotate/cerniq-backup ]; then
              sudo cp /opt/cerniq/config/logrotate/cerniq-backup /etc/logrotate.d/cerniq-backup
              echo "‚úÖ Logrotate configured"
            fi
          ENDSSH

      # =========================================================================
      # STEP 9: Health Check and verification (SMOKE TESTS)
      # =========================================================================
      - name: üß™ Verify Production Deployment (Smoke Tests)
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }} << 'ENDSSH'
            echo "========================================"
            echo "  PRODUCTION DEPLOYMENT SMOKE TESTS"
            echo "========================================"
            
            cd /opt/cerniq
            FAILED=0
            
            echo ""
            echo "üìä Container Status"
            docker ps --format 'table {{.Names}}\t{{.Status}}' | grep cerniq | sort
            
            echo ""
            echo "üîç Core Services Health Checks"
            
            # External PostgreSQL reachability (CT107)
            echo -n "  PostgreSQL: "
            if docker run --rm --network host postgres:18 pg_isready -h 10.0.1.107 -p 5432 >/dev/null 2>&1; then
              echo "‚úÖ HEALTHY"
            else
              echo "‚ùå FAILED"
              FAILED=1
            fi
            
            # PgBouncer + OpenBao dynamic creds (end-to-end)
            echo -n "  PgBouncer:  "
            if docker run --rm --network cerniq_backend \
              --env-file /run/cerniq/runtime-secrets/api/api.env \
              postgres:18 sh -c 'psql "$DATABASE_URL" -Atqc "SELECT 1"' >/dev/null 2>&1; then
              echo "‚úÖ HEALTHY"
            else
              echo "‚ö†Ô∏è NOT READY (may be initializing)"
            fi
            
            # Redis health
            echo -n "  Redis:      "
            if docker run --rm --network host \
              --env-file /run/cerniq/runtime-secrets/api/api.env \
              redis:8-alpine sh -c 'redis-cli -u "$REDIS_URL" PING' 2>/dev/null | grep -q PONG; then
              echo "‚úÖ HEALTHY"
            else
              echo "‚ùå FAILED"
              FAILED=1
            fi
            
            # Ingress health via orchestrator Traefik
            echo -n "  Ingress:    "
            if curl -skf https://cerniq.app >/dev/null 2>&1; then
              echo "‚úÖ HEALTHY"
            else
              echo "‚ùå FAILED"
              FAILED=1
            fi
            
            # Vector health
            echo -n "  Vector:     "
            if docker inspect -f '{{.State.Running}}' cerniq-vector 2>/dev/null | grep -q true; then
              echo "‚úÖ HEALTHY"
            else
              echo "‚ùå FAILED"
              FAILED=1
            fi

            # OpenBao agents health (remote OpenBao on orchestrator)
            echo -n "  OpenBao:    "
            if docker inspect -f '{{.State.Health.Status}}' cerniq-openbao-agent-api 2>/dev/null | grep -q healthy && \
               docker inspect -f '{{.State.Health.Status}}' cerniq-openbao-agent-workers 2>/dev/null | grep -q healthy && \
               docker inspect -f '{{.State.Health.Status}}' cerniq-openbao-agent-infra 2>/dev/null | grep -q healthy; then
              echo "‚úÖ HEALTHY (agents)"
            else
              echo "‚ùå FAILED (agents)"
              FAILED=1
            fi
            
            echo ""
            echo "üîê Security Services"
            
            # fail2ban
            echo -n "  fail2ban:   "
            if sudo systemctl is-active fail2ban >/dev/null 2>&1; then
              echo "‚úÖ ACTIVE"
            else
              echo "‚ö†Ô∏è INACTIVE"
            fi
            
            # UFW
            echo -n "  UFW:        "
            if sudo ufw status | grep -q "Status: active"; then
              echo "‚úÖ ACTIVE"
            else
              echo "‚ö†Ô∏è INACTIVE"
            fi
            
            echo ""
            echo "========================================"
            if [ $FAILED -eq 0 ]; then
              echo "‚úÖ ALL SMOKE TESTS PASSED"
              echo "Production deployment complete - version ${{ needs.setup.outputs.version }}"
            else
              echo "‚ùå SOME SMOKE TESTS FAILED"
              echo "Review the failures above and check container logs"
              exit 1
            fi
            echo "========================================"
          ENDSSH

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ needs.setup.outputs.version }}
          name: "Release ${{ needs.setup.outputs.version }}"
          generate_release_notes: true
          draft: false
          prerelease: ${{ !startsWith(needs.setup.outputs.version, 'v1.') }}

  # ===========================================================================
  # JOB 5: Post-Deployment Summary
  # ===========================================================================
  summary:
    name: üìã Deployment Summary
    runs-on: self-hosted
    needs: [setup, deploy-staging, deploy-production]
    if: always() && (needs.deploy-staging.result == 'success' || needs.deploy-production.result == 'success')

    steps:
      - name: üìã Generate Summary
        run: |
          echo "## üöÄ Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Property | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Environment | ${{ needs.setup.outputs.environment }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Version | ${{ needs.setup.outputs.version }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Commit | ${{ needs.setup.outputs.sha }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ‚úÖ Deployment Steps Completed" >> $GITHUB_STEP_SUMMARY
          echo "- Configuration files synced" >> $GITHUB_STEP_SUMMARY
          echo "- Docker services deployed" >> $GITHUB_STEP_SUMMARY
          echo "- OpenBao initialized and configured" >> $GITHUB_STEP_SUMMARY
          echo "- Firewall configured" >> $GITHUB_STEP_SUMMARY
          echo "- System configs installed (fail2ban, cron)" >> $GITHUB_STEP_SUMMARY
          echo "- Smoke tests passed" >> $GITHUB_STEP_SUMMARY

  # ===========================================================================
  # JOB 6: Rollback (Manual Trigger Only)
  # ===========================================================================
  rollback:
    name: ‚èÆÔ∏è Rollback Deployment
    runs-on: self-hosted
    if: github.event_name == 'workflow_dispatch' && inputs.environment != ''
    environment:
      name: ${{ inputs.environment }}

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üîß Setup SSH
        run: |
          mkdir -p ~/.ssh
          if [[ "${{ inputs.environment }}" == "production" ]]; then
            echo "${{ secrets.PRODUCTION_SSH_KEY }}" > ~/.ssh/deploy_key
            echo "HOST=${{ secrets.PRODUCTION_HOST }}" >> $GITHUB_ENV
            echo "USER=${{ secrets.PRODUCTION_USER }}" >> $GITHUB_ENV
          else
            echo "${{ secrets.STAGING_SSH_KEY }}" > ~/.ssh/deploy_key
            echo "HOST=${{ secrets.STAGING_HOST }}" >> $GITHUB_ENV
            echo "USER=${{ secrets.STAGING_USER }}" >> $GITHUB_ENV
          fi
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H $HOST >> ~/.ssh/known_hosts 2>/dev/null

      - name: ‚èÆÔ∏è Execute Rollback
        run: |
          ssh -i ~/.ssh/deploy_key ${USER}@${HOST} << 'ENDSSH'
            cd /opt/cerniq
            
            echo "========================================"
            echo "  ROLLBACK DEPLOYMENT"
            echo "========================================"
            
            # Check for previous version
            if [ ! -f /opt/cerniq/.previous_deploy ]; then
              echo "‚ùå No previous deployment found!"
              echo "   Cannot rollback without .previous_deploy file"
              exit 1
            fi
            
            PREV_VERSION=$(cat /opt/cerniq/.previous_deploy)
            echo "üìã Rolling back to: $PREV_VERSION"
            
            # Resolve previous tag and export for compose (if image tags are parameterized)
            echo "üê≥ Reverting to previous images..."
            if [[ "$PREV_VERSION" == sha-* || "$PREV_VERSION" == v* || "$PREV_VERSION" == *-* ]]; then
              export CERNIQ_VERSION="$PREV_VERSION"
            fi
            docker compose -f docker-compose.yml -f docker-compose.prod.yml pull --ignore-pull-failures || true
            
            # Restart services
            echo "üîÑ Restarting services..."
            docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d --force-recreate --remove-orphans
            
            echo ""
            echo "‚è≥ Waiting for services..."
            sleep 15
            
            # Verify
            echo ""
            echo "üìä Container Status after rollback:"
            docker ps --format 'table {{.Names}}\t{{.Status}}' | grep cerniq | sort
            
            echo ""
            echo "‚úÖ Rollback complete"
          ENDSSH

      - name: üìã Generate Rollback Summary
        run: |
          echo "## ‚èÆÔ∏è Rollback Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Environment: ${{ inputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "Triggered by: ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
