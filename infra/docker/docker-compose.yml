# ============================================================================
# Cerniq.app - Docker Compose Base Configuration
# ============================================================================
# Version: 1.0.1
# Last Updated: 2026-02-03
# References: ADR-0015, ADR-0022, ADR-0027
# ============================================================================
# IMPORTANT: Networks are created externally via `docker network create`
# to ensure proper isolation and persistence across compose restarts.
# See: docs/infrastructure/network-topology.md
# ============================================================================

name: cerniq

# ============================================================================
# Networks (External)
# ============================================================================
# Networks are pre-created on servers (staging/production) with:
#   docker network create --subnet X.X.X.X/24 [--internal] <name>
#
# Subnets (avoiding conflicts with GeniusERP/Neanelu on staging):
# - cerniq_public:  172.27.0.0/24 (external access via Traefik)
# - cerniq_backend: 172.28.0.0/24 (internal: API + Workers)
# - cerniq_data:    172.29.0.0/24 (internal: PostgreSQL + Redis)
# ============================================================================

networks:
  cerniq_public:
    external: true
  cerniq_backend:
    external: true
  cerniq_data:
    external: true

# ============================================================================
# Volumes
# ============================================================================
# Persistent storage for databases and application data
# ============================================================================

volumes:
  # PostgreSQL data persistence
  postgres_data:
    driver: local

  # PostgreSQL WAL archive for PITR
  postgres_wal_archive:
    driver: local

  # Redis data persistence (RDB snapshots)
  redis_data:
    driver: local

  # Traefik certificates (Let's Encrypt)
  traefik_certs:
    driver: local

  # SigNoz/ClickHouse data
  signoz_data:
    driver: local

# ============================================================================
# X-Common Configurations (YAML Anchors)
# ============================================================================
# Reusable configuration blocks for services
# ============================================================================

x-common-labels: &common-labels
  com.cerniq.app: "cerniq"
  com.cerniq.environment: "${CERNIQ_ENV:-development}"
  com.cerniq.version: "${CERNIQ_VERSION:-0.0.0}"

x-logging: &default-logging
  driver: json-file
  options:
    max-size: "50m"
    max-file: "5"

x-healthcheck-defaults: &healthcheck-defaults
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s

# Resource limits - STAGING CONFIGURATION
# Current: Staging server (125GB RAM, 64 cores AMD EPYC)
# Target (ADR-0027): Production server (128GB RAM, 20 cores)
# WARNING: These are TEMPORARY limits. See docs/infrastructure/RESOURCE-UPGRADE-PLAN.md
# TODO: Reconfigure when production server is upgraded

x-resource-api: &resource-api
  limits:
    memory: 4G
    cpus: '2'
  reservations:
    memory: 2G
    cpus: '1'

x-resource-worker: &resource-worker
  limits:
    memory: 2G
    cpus: '1'
  reservations:
    memory: 1G
    cpus: '0.5'

x-resource-postgres: &resource-postgres
  limits:
    memory: 16G
    cpus: '4'
  reservations:
    memory: 8G
    cpus: '2'

x-resource-postgres-production: &resource-postgres-production
  limits:
    memory: 4G
    cpus: '2'
  reservations:
    memory: 2G
    cpus: '1'

x-resource-redis: &resource-redis
  limits:
    memory: 4G
    cpus: '1'
  reservations:
    memory: 2G
    cpus: '0.5'

x-resource-signoz: &resource-signoz
  limits:
    memory: 4G
    cpus: '1'
  reservations:
    memory: 2G
    cpus: '0.5'

x-resource-traefik: &resource-traefik
  limits:
    memory: 512M
    cpus: '0.5'
  reservations:
    memory: 256M
    cpus: '0.25'

# ============================================================================
# Secrets
# ============================================================================
# Docker secrets for sensitive data (passwords, keys)
# Reference: etapa0-docker-secrets-guide.md
# ============================================================================

secrets:
  postgres_password:
    file: ../../secrets/postgres_password.txt
  redis_password:
    file: ../../secrets/redis_password.txt

# ============================================================================
# Services
# ============================================================================
# E0-S2-PR02: PostgreSQL 18.1 + PgBouncer
# ============================================================================

services:
  # ==========================================================================
  # PostgreSQL 18.1 with PostGIS 3.6 + pgvector 0.8
  # ==========================================================================
  # Reference: ADR-0004, etapa0-plan-implementare-complet-v2.md
  # Extensions: pgvector 0.8.1, PostGIS 3.6.1, pg_trgm
  # Port: 5432 (internal only, accessed via cerniq_data network)
  # ==========================================================================
  postgres:
    build:
      context: ./postgres
      dockerfile: Dockerfile
    image: cerniq/postgres:18-pgvector
    container_name: cerniq-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: c3rn1q
      POSTGRES_DB: cerniq
      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password
      PGDATA: /var/lib/postgresql/data/pgdata
      POSTGRES_INITDB_ARGS: "--data-checksums"
    secrets:
      - postgres_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - postgres_wal_archive:/var/lib/postgresql/wal_archive
      - ../config/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ../config/postgres/init.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
    networks:
      cerniq_data:
        ipv4_address: 172.29.0.10
    # NO ports exposed - internal network only (security)
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U c3rn1q -d cerniq -h localhost -p 5432"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        <<: *resource-postgres
    shm_size: 4g
    command: 
      - "postgres"
      - "-c"
      - "config_file=/etc/postgresql/postgresql.conf"
    labels:
      <<: *common-labels
      com.cerniq.service: "postgres"
      com.cerniq.port: "5432"
    logging:
      <<: *default-logging

  # ==========================================================================
  # PgBouncer 1.23 - Connection Pooling
  # ==========================================================================
  # Reference: pgbouncer-connection-pooling.md, ADR-0004
  # Port: 6432 (internal only, accessed via cerniq_data + cerniq_backend)
  # ==========================================================================
  pgbouncer:
    image: edoburu/pgbouncer:latest
    container_name: cerniq-pgbouncer
    restart: unless-stopped
    environment:
      DATABASE_URL: postgres://c3rn1q:${POSTGRES_PASSWORD}@postgres:5432/cerniq
      POOL_MODE: transaction
      MAX_CLIENT_CONN: 1000
      DEFAULT_POOL_SIZE: 50
      MIN_POOL_SIZE: 10
      RESERVE_POOL_SIZE: 20
      RESERVE_POOL_TIMEOUT: 5
      AUTH_TYPE: scram-sha-256
      IGNORE_STARTUP_PARAMETERS: extra_float_digits
      SERVER_RESET_QUERY: DISCARD ALL
      # Logging
      LOG_CONNECTIONS: 1
      LOG_DISCONNECTIONS: 1
      VERBOSE: 0
    networks:
      cerniq_data:
        ipv4_address: 172.29.0.11
      cerniq_backend:
        ipv4_address: 172.28.0.11
    # NO ports exposed - internal network only (security)
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h localhost -p 5432 -U c3rn1q || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    labels:
      <<: *common-labels
      com.cerniq.service: "pgbouncer"
      com.cerniq.port: "6432"
    logging:
      <<: *default-logging

  # ==========================================================================
  # Redis 8.4.0 Alpine - BullMQ Job Queues & Cache
  # ==========================================================================
  # Reference: ADR-0006, etapa0-plan-implementare-complet-v2.md
  # CRITICAL: maxmemory-policy MUST be noeviction for BullMQ
  # Port: 6379 (internal only, accessed via cerniq_data + cerniq_backend)
  # ==========================================================================
  redis:
    image: redis:8.4-alpine
    container_name: cerniq-redis
    restart: unless-stopped
    secrets:
      - redis_password
    command:
      - /bin/sh
      - -c
      - |
        redis-server \
          --port 6379 \
          --requirepass "$$(cat /run/secrets/redis_password)" \
          --maxmemory 4gb \
          --maxmemory-policy noeviction \
          --appendonly yes \
          --appendfsync everysec \
          --aof-use-rdb-preamble yes \
          --notify-keyspace-events Ex \
          --lazyfree-lazy-eviction yes \
          --lazyfree-lazy-expire yes \
          --lazyfree-lazy-server-del yes \
          --activedefrag yes \
          --tcp-keepalive 300 \
          --timeout 0 \
          --databases 16
    volumes:
      - redis_data:/data
    networks:
      cerniq_data:
        ipv4_address: 172.29.0.20
      cerniq_backend:
        ipv4_address: 172.28.0.20
    # NO ports exposed - internal network only (security)
    healthcheck:
      test: ["CMD-SHELL", "redis-cli -a \"$$(cat /run/secrets/redis_password)\" ping | grep -q PONG"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        <<: *resource-redis
    labels:
      <<: *common-labels
      com.cerniq.service: "redis"
      com.cerniq.port: "6379"
    logging:
      <<: *default-logging
