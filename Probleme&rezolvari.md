# CERNIQ.APP â€” PROBLEME DESCOPERITE & REZOLVÄ‚RI

## Audit Complet Sprint 1â€“4 (Etapa 0)

**Data Audit:** 5 Februarie 2026  
**Scope:** Audit complet pe 7 direcÈ›ii: Sprint 1-4 contracte, CI/CD, Docker+Secrete, Teste, Staging, ProducÈ›ie  
**Status:** Probleme identificate, rezolvÄƒri documentate

---

## CONTEXT MEDIU â€” APLICAÈšII COEXISTENTE PE SERVERE

> **ATENÈšIE:** Fiecare server ruleazÄƒ multiple proiecte. Orice modificare Cerniq **NU trebuie** sÄƒ afecteze celelalte aplicaÈ›ii.

---

### SERVER STAGING â€” 135.181.183.164

| Parametru | Valoare |
|-----------|---------|
| **OS** | Ubuntu 24.04.3 LTS |
| **CPU** | 64 cores AMD EPYC |
| **RAM** | 125 GiB total, ~101 GiB disponibil |
| **Disk** | 875 GB NVMe, 116 GB folosit (14%) |
| **Docker** | 29.1.3 / Compose v5.0.1 |
| **UFW** | ACTIV â€” allow 22, 80, 443, 5000-5002 |

#### Proiecte active pe staging

| Proiect | Containere | Porturi | RAM | Note |
|---------|-----------|---------|-----|------|
| **Cerniq** (8 containere) | postgres, redis, traefik, pgbouncer, openbao, openbao-agent-api, openbao-agent-workers, staging-proxy | 64080, 64093 (127.0.0.1), 64094 | ~335 MiB | ReÈ›ele: 172.29.10/20/30.0/24 |
| **Neanelu Shopify** (12 containere) | traefik, web_admin, backend_worker, postgres, redis, otel_collector, jaeger, promtail, alertmanager, loki, prometheus, grafana, redis_commander, bull_board | 80, 443, 65010, 65023-65025, 65031-65032 | ~1.5 GiB | ReÈ›ele: 172.19.0.0/16, 172.24.0.0/16, 172.25.0.0/16 |
| **GeniusSuite** (26 containere) | traefik, 12Ã— suite-apps (cerniq, geniuserp, mercantiq, flowxify, etc.), postgres, neo4j, kafka, temporal, supertokens, openbao, grafana, prometheus, loki, tempo, otel, promtail | 6100-6400, 8088, 8445, 8000, 8080 (127.0.0.1), 8200 (127.0.0.1) | ~3.1 GiB | ReÈ›ele: 172.20-23.0.0/16 |
| **TLC4Pipes** (3 containere) | frontend, backend, db | 8811, 8000 | ~142 MiB | ReÈ›ea: 172.18.0.0/16 |

#### Servicii host staging

| Serviciu | Port | Note |
|----------|------|------|
| SSH | 22 | Standard |
| Nginx | 64443 (SSL) | proxy_pass â†’ cerniq_traefik |
| Postfix | 25 (localhost) | Mail relay |
| Redis (host) | 6379 (localhost) | Separat de Docker Redis |
| PHP-FPM 8.3 | â€” | Legacy, activ |
| GitHub Actions Runner | â€” | `cerniq-runner-1` activ |

#### ReÈ›ele Docker staging â€” NO-GO subnets

| ReÈ›ea | Subnet | Proprietar |
|-------|--------|-----------|
| cerniq_public | 172.29.10.0/24 | Cerniq |
| cerniq_backend | 172.29.20.0/24 | Cerniq |
| cerniq_data | 172.29.30.0/24 | Cerniq |
| neanelu_network | 172.19.0.0/16 | Neanelu |
| neanelu_public_net | 172.24.0.0/16 | Neanelu |
| neanelu_frontend_network | 172.25.0.0/16 | Neanelu |
| docker_tlc4pipes_net | 172.18.0.0/16 | TLC4Pipes |
| geniuserp_net_edge | 172.20.0.0/16 | GeniusSuite |
| geniuserp_net_suite_internal | 172.21.0.0/16 | GeniusSuite |
| geniuserp_net_backing_services | 172.22.0.0/16 | GeniusSuite |
| geniuserp_net_observability | 172.23.0.0/16 | GeniusSuite |

#### SSL Certificates staging

| Domeniu | Provider |
|---------|----------|
| staging.cerniq.app | Let's Encrypt |
| geniuserp.app | Let's Encrypt |
| manager.neanelu.ro | Let's Encrypt |

#### Cron staging

| FrecvenÈ›Äƒ | Task |
|-----------|------|
| Zilnic 02:00 | Backup Hetzner Storage Box |
| Zilnic 03:00 | Borg full system backup |
| Zilnic 01:00 | Docker disk monitor (limitÄƒ 60GB) |
| Zilnic 04:00 | rkhunter security scan |

#### Docker resources staging

| ResursÄƒ | Valoare |
|---------|---------|
| Images | 110 (30.76 GB, 14.95 GB reclaimable) |
| Containers | 58 (toate active) |
| Volumes | 147 (32.92 GB) |
| Build Cache | 302 entries (16.6 GB, 1.16 GB reclaimable) |

---

### SERVER PRODUCÈšIE â€” 95.216.225.145

| Parametru | Valoare |
|-----------|---------|
| **OS** | Ubuntu 22.04.5 LTS (Proxmox LXC, kernel 5.15) |
| **CPU** | 4 cores (AMD Ryzen 7 PRO 1700X, 12/16 offline) |
| **RAM** | 10 GiB total, ~8.4 GiB disponibil |
| **Disk** | 49 GB total, **35 GB folosit (76%)** â€” doar **12 GB liber** |
| **Swap** | 1 GiB (487 MiB utilizat) |
| **Docker** | 28.3.3 / Compose v2.39.1 |
| **UFW** | âš ï¸ **INACTIV** (Proxmox LXC â€” poate nu funcÈ›ioneazÄƒ) |
| **Uptime** | 259 zile |

#### Proiecte active pe producÈ›ie

| Proiect | Containere | Porturi | RAM | Note |
|---------|-----------|---------|-----|------|
| **Cerniq** (8 containere) | postgres, redis, traefik, pgbouncer, openbao, openbao-agent-api (unhealthy), openbao-agent-workers (unhealthy), staging-proxy | 64080, 64081 (127.0.0.1), 64090 (127.0.0.1) | ~552 MiB | ReÈ›ele: 172.27.0.0/24, 172.28.0.0/24, 172.29.0.0/24 |
| **WAppBuss** (4 containere) | backend, frontend, postgres:15, redis:7 | 3060, 3061, **3062 (PG!)**, **3063 (Redis!)** â€” toate pe 0.0.0.0 | ~131 MiB | ReÈ›ea: 172.18.0.0/16; **DB+Redis expuse pe internet!** |
| **IWMS** (nativ, PM2) | uvicorn (Python), vite (Node) | **3000**, **3002** â€” pe 0.0.0.0 | ~577 MiB | DB: `gestiune_marfa` pe host PG :5433 |
| **WMS v1** (systemd) | vite frontend | **5173** â€” pe 0.0.0.0 | ~110 MiB | DB: SQLite, systemd service |

#### AplicaÈ›ii inactive/legacy pe producÈ›ie (candidaÈ›i È™tergere)

| Proiect | Disk | Note |
|---------|------|------|
| GeniusERPv5.4.1 | 2.6 GB | /var/www/GeniusERPv5.4.1 â€” de arhivat |
| GeniusERP | 582 MB | /var/www/GeniusERP â€” de arhivat |
| seceta | 399 MB | /var/www/seceta â€” de arhivat |
| Neanelu/Medusa | â€” | Multiple DB-uri Ã®n host PG, fÄƒrÄƒ containere active |
| **Total recuperabil** | **~3.6 GB** | + 1.27 GB Docker build cache |

#### Servicii host producÈ›ie

| Serviciu | Port | Note |
|----------|------|------|
| SSH | 22 | Standard |
| Nginx | 80, 443 | Reverse proxy: cerniq.app â†’ :64080, IWMS â†’ :3000/:3002, WAppBuss â†’ :3060/:3061 |
| PostgreSQL 17 (host) | 5433 (localhost) | DB-uri: gestiune_marfa (IWMS), geniuserp2025, medusa-*, seceta_db |
| Postfix | 25 (localhost) | Mail relay |
| Fail2ban | â€” | Activ |
| PM2 | â€” | GestioneazÄƒ IWMS (dev user) |
| wms-frontend.service | â€” | Systemd service WMS v1 |
| Certbot cron | â€” | ReÃ®nnoire SSL cerniq.app (exp. 4 Mai 2026) |
| acme.sh cron | â€” | ReÃ®nnoire SSL dev.neanelu.ro |

#### ReÈ›ele Docker producÈ›ie â€” NO-GO subnets

| ReÈ›ea | Subnet | Proprietar |
|-------|--------|-----------|
| cerniq_public | 172.27.0.0/24 | Cerniq |
| cerniq_backend | 172.28.0.0/24 | Cerniq |
| cerniq_data | 172.29.0.0/24 | Cerniq |
| wappbuss_default | 172.18.0.0/16 | WAppBuss |

#### Resource overcommit producÈ›ie (**CRITICÄ‚**)

Compose YAML anchors alocÄƒ limite care **depÄƒÈ™esc RAM-ul total de 10 GiB**:

| Serviciu | LimitÄƒ Compose | Utilizare realÄƒ |
|----------|---------------|----------------|
| cerniq-postgres | 16 GiB (**!**) | 246 MiB |
| cerniq-redis | 4 GiB | 27 MiB |
| cerniq-traefik | 512 MiB | 182 MiB |
| cerniq-openbao | 512 MiB | 42 MiB |
| cerniq-agents (2Ã—) | 128 MiB Ã— 2 | 30 MiB |
| cerniq-pgbouncer | 256 MiB | 11 MiB |
| **Total alocat** | **~21.5 GiB** | **~538 MiB** |
| **RAM disponibil** | **10 GiB** | â€” |

> **FIX NECESAR:** Trebuie activat compose overlay `docker-compose.prod.yml` cu `x-resource-postgres-production` (4 GiB), `x-resource-redis-production` etc.  
> Limita PG de 16G va cauza OOM kills sub sarcinÄƒ pe producÈ›ie.
> **Implementare:** Exclusiv prin CI/CD (push Ã®n `main`). Nu se ruleazÄƒ manual pe producÈ›ie.

#### Disk breakdown producÈ›ie

| Path | Size |
|------|------|
| /var/www/GeniusERPv5.4.1 | 2.6 GB |
| /var/www/IWMS | 1.1 GB |
| /home/iwms-user | 1.1 GB |
| /home/gestiune | 760 MB |
| /var/www/GeniusERP | 582 MB |
| /var/www/seceta | 399 MB |
| /var/www/wms | 374 MB |
| /home/dev | 346 MB |
| Docker images | 3.0 GB (454 MB reclaimable) |
| Docker build cache | 1.27 GB (fully reclaimable) |
| Docker volumes | 236 MB |

#### Cron producÈ›ie

| FrecvenÈ›Äƒ | Task |
|-----------|------|
| Orar | Critical PG dumps |
| Zilnic | Full PG dumps |
| SÄƒptÄƒmÃ¢nal | Base backups |
| Orar | Redis snapshots |
| Zilnic | Borg backup â†’ Hetzner Storage Box |
| Lunar | Restore test automat |

---

### CONSTRÃ‚NGERI CRITICE PENTRU IMPLEMENTARE

> Toate fixurile din acest document **TREBUIE** sÄƒ respecte aceste constrÃ¢ngeri:

#### ProducÈ›ie â€” reguli stricte

1. **RAM limitat la 10 GiB** â€” totalul limitelor Docker + IWMS (~577M) + WMS (~110M) + WAppBuss (~131M) + host PG nu trebuie sÄƒ depÄƒÈ™eascÄƒ 10 GiB
2. **Disk la 76%** â€” nu instala nimic nou fÄƒrÄƒ curÄƒÈ›are prealabilÄƒ (docker system prune, arhivare legacy apps)
3. **Nu modifica porturile:** 3060-3063 (WAppBuss), 3000/3002 (IWMS), 5173 (WMS), 5433 (host PG)
4. **Nu modifica reÈ›elele:** wappbuss_default (172.18.0.0/16)
5. **Nu modifica Nginx vhosts:** cerniq.app, IWMS, WAppBuss â€” fiecare are configuraÈ›ie separatÄƒ
6. **UFW:** Pe Proxmox LXC s-ar putea sÄƒ nu funcÈ›ioneze â€” testeazÄƒ `ufw enable` manual Ã®nainte de script
7. **Certbot/acme.sh:** Nu modifica â€” SSL se reÃ®nnoieÈ™te automat
8. **PM2 / systemd WMS:** Nu modifica â€” IWMS È™i WMS ruleazÄƒ independent de Docker
9. **ReÈ›ele Docker producÈ›ie** folosesc subnets DIFERITE de staging: 172.27/28/29.0.0/24 vs 172.29.10/20/30.0/24
10. **Implementare producÈ›ie:** Orice schimbare se face **exclusiv prin CI/CD**, declanÈ™atÄƒ de push Ã®n `main`.

#### Staging â€” reguli stricte

1. **58 containere active** â€” 4 proiecte coexistente (Cerniq, Neanelu, GeniusSuite, TLC4Pipes)
2. **Nu modifica reÈ›elele:** neanelu_* (172.19/24/25.0.0/16), geniuserp_* (172.20-23.0.0/16), docker_tlc4pipes_net (172.18.0.0/16)
3. **Neanelu Traefik** gestioneazÄƒ porturile 80/443 â€” Cerniq Traefik ascultÄƒ pe 64080 **Ã®n spatele** Nginx :64443
4. **Nu modifica UFW staging** â€” regulile existente (22, 80, 443, 5000-5002) sunt corecte
5. **GitHub Actions Runner** â€” serviciu `actions.runner.*.service` activ, nu opri/reporni
6. **Host Redis** (port 6379 localhost) â€” nu confunda cu Docker cerniq-redis

---

## CUPRINS

1. [CRITICE â€” PRODUCÈšIE](#1-critice--producÈ›ie)
2. [CRITICE â€” STAGING](#2-critice--staging)
3. [CRITICE â€” REPO/CI/CD](#3-critice--repocicd)
4. [DOCUMENTAÈšIE â€” ADR-uri stale](#4-documentaÈ›ie--adr-uri-stale)
5. [CI/CD â€” Gapuri pipeline](#5-cicd--gapuri-pipeline)
6. [TESTE â€” Gapuri infrastructure](#6-teste--gapuri-infrastructurÄƒ)
7. [SECURITATE â€” Staging & General](#7-securitate--staging--general)
8. [ORDINE IMPLEMENTARE](#8-ordine-implementare)

---

## 1. CRITICE â€” PRODUCÈšIE

### C1. UFW Firewall INACTIV pe producÈ›ie

**Severitate:** ğŸ”´ CRITICÄ‚  
**Server:** 95.216.225.145 (producÈ›ie)  
**Problema:** Firewall-ul UFW este **dezactivat**. Porturile 3060-3063 (WappBuss PostgreSQL + Redis) sunt expuse direct pe internet. Oricine poate accesa baza de date WappBuss fÄƒrÄƒ autentificare de reÈ›ea.

**Descoperire:**
```
root@erp:~# ufw status
Status: inactive
```

Porturi expuse public fÄƒrÄƒ protecÈ›ie:
| Port | Serviciu | Risc |
|------|----------|------|
| 3062 | WappBuss PostgreSQL | DB pe internet |
| 3063 | WappBuss Redis | Cache pe internet |
| 5173 | Vite dev server | Dev server pe producÈ›ie |
| 3000, 3002 | Node/Python servers | AplicaÈ›ii neprotejate |

**Rezolvare (adaptat producÈ›ie LXC + proiecte coexistente):**
**Implementare:** Exclusiv prin CI/CD (push Ã®n `main`). Nu se ruleazÄƒ manual pe producÈ›ie.
1. **ConfirmÄƒ cÄƒ UFW funcÈ›ioneazÄƒ Ã®n LXC** (pe Proxmox uneori nu aplicÄƒ reguli). DacÄƒ `ufw enable` nu modificÄƒ traficul, foloseÈ™te firewall pe host Proxmox.
2. **Nu bloca porturile proiectelor existente** Ã®nainte de a valida accesul:
  - IWMS: 3000/3002
  - WMS v1: 5173
  - WAppBuss: 3060/3061 (frontend/backend)
3. **BlocheazÄƒ doar DB/Redis expuse** (3062/3063) dupÄƒ ce confirmi cÄƒ WAppBuss nu le foloseÈ™te extern.

```bash
# Rulat automat prin CI/CD pe runner-ul de producÈ›ie
ufw default deny incoming
ufw default allow outgoing
ufw allow 22/tcp
ufw allow 80/tcp
ufw allow 443/tcp
# MenÈ›ine temporar porturile de aplicaÈ›ii pÃ¢nÄƒ confirmi dependinÈ›ele
ufw allow 3000/tcp
ufw allow 3002/tcp
ufw allow 5173/tcp
ufw allow 3060/tcp
ufw allow 3061/tcp

# DupÄƒ validare, blocheazÄƒ DB/Redis expuse
ufw deny 3062/tcp
ufw deny 3063/tcp

ufw enable
ufw status verbose
```

**NotÄƒ:** DacÄƒ UFW nu aplicÄƒ reguli Ã®n LXC, mutÄƒ filtrarea pe firewall-ul Proxmox È™i Ã®n Nginx (deny IP) pentru 3062/3063.

**Implementare exclusiv prin CI/CD (push Ã®n main):**
- ActualizeazÄƒ `.github/workflows/deploy.yml` cu paÈ™ii UFW pentru producÈ›ie È™i ruleazÄƒ doar prin pipeline (self-hosted runner).
- Nu rula manual comenzi pe producÈ›ie; orice modificare UFW se face doar prin deploy-ul automat declanÈ™at de push Ã®n `main`.

**FiÈ™iere de actualizat:**
- `infra/scripts/setup-firewall.sh` â€” verificÄƒ cÄƒ include reguli pentru producÈ›ie
- `.github/workflows/deploy.yml` â€” adaugÄƒ step de activare UFW Ã®n deploy producÈ›ie

---

### C2. OpenBao Agents crash loop pe producÈ›ie (403 Forbidden)

**Severitate:** ğŸ”´ CRITICÄ‚  
**Server:** 95.216.225.145 (producÈ›ie)  
**Problema:** Ambii OpenBao Agents (`cerniq-openbao-agent-api` È™i `cerniq-openbao-agent-workers`) sunt UNHEALTHY cu 15-16 restartÄƒri. Eroarea: `403 permission denied` la accesul `database/creds/api-role`.

**Descoperire:**
```
cerniq-openbao-agent-api       Up 3 hours (unhealthy)    16 restarts
cerniq-openbao-agent-workers   Up 3 hours (unhealthy)    15 restarts

Error: 1 error occurred:
  * error preflight capability check: Error making API request. Code: 403
  URL: PUT https://openbao:8200/v1/sys/capabilities-self
  Message: permission denied
```

**Cauza root:** Politicile OpenBao nu au fost configurate pe producÈ›ie. Scripturile `openbao-setup-engines.sh` È™i `openbao-setup-approle.sh` nu au fost rulate dupÄƒ init.

**Rezolvare (adaptat producÈ›ie):**
**Implementare:** Exclusiv prin CI/CD (push Ã®n `main`). Nu se ruleazÄƒ manual pe producÈ›ie.
```bash
# Rulat automat prin CI/CD pe runner-ul de producÈ›ie
cd /opt/cerniq

# 1. Setare OPENBAO_ADDR
export OPENBAO_ADDR="http://127.0.0.1:64090"
export OPENBAO_TOKEN=$(cat secrets/openbao_root_token.txt)

# 2. Configurare engines
bash scripts/openbao-setup-engines.sh

# 3. Configurare AppRole
bash scripts/openbao-setup-approle.sh

# 4. Populare secrete KV
docker exec -e BAO_ADDR=http://127.0.0.1:8200 \
  -e BAO_TOKEN=$OPENBAO_TOKEN \
  cerniq-openbao bao kv put secret/cerniq/database \
    pg_user=c3rn1q \
    pg_password=$(cat secrets/postgres_password.txt) \
    pg_host=pgbouncer \
    pg_port=64033 \
    pg_database=cerniq

docker exec -e BAO_ADDR=http://127.0.0.1:8200 \
  -e BAO_TOKEN=$OPENBAO_TOKEN \
  cerniq-openbao bao kv put secret/cerniq/redis \
    password=$(cat secrets/redis_password.txt) \
    host=redis \
    port=64039

# 5. Restart agents
docker compose -f docker-compose.yml -f docker-compose.prod.yml restart openbao-agent-api openbao-agent-workers
```

**NotÄƒ:** RuleazÄƒ scripturile OpenBao **doar** Ã®n intervale cu trafic minim pentru a evita impact asupra IWMS/WAppBuss (resurse limitate).

**Implementare exclusiv prin CI/CD (push Ã®n main):**
- AdaugÄƒ Ã®n `.github/workflows/deploy.yml` un pas explicit pentru `scripts/openbao-setup-engines.sh` È™i `scripts/openbao-setup-approle.sh` Ã®n targetul production.
- Rularea se face automat la push Ã®n `main`; nu executa manual aceste scripturi pe producÈ›ie.

**FiÈ™iere de verificat:**
- `infra/config/openbao/policies/api-policy.hcl` â€” trebuie sÄƒ includÄƒ `database/creds/api-role`
- `infra/config/openbao/policies/workers-policy.hcl` â€” trebuie sÄƒ includÄƒ `database/creds/workers-role`
- `.github/workflows/deploy.yml` â€” verificÄƒ cÄƒ deploy production ruleazÄƒ setup OpenBao complet

---

### C3. postgresql.conf de STAGING folosit pe PRODUCÈšIE

**Severitate:** ğŸ”´ CRITICÄ‚  
**Server:** 95.216.225.145 (producÈ›ie, 10GB RAM, 4 cores)  
**Problema:** FiÈ™ierul `postgresql.conf` deploiat pe producÈ›ie este cel de staging (configurat pentru 125GB RAM / 64 cores). `shared_buffers = 4GB` È™i `effective_cache_size = 12GB` pe un server cu doar 10GB RAM total.

**Descoperire:**
```
# Header din fiÈ™ier:
# PostgreSQL 18.1 Configuration for Cerniq.app - STAGING
# Environment: Staging (125GB RAM, 64 cores AMD EPYC)
# Allocated: 16GB RAM for PostgreSQL
```

**Rezolvare (adaptat producÈ›ie 10GB RAM):**
**Implementare:** Exclusiv prin CI/CD (push Ã®n `main`). Nu se ruleazÄƒ manual pe producÈ›ie.
1. Deploy.yml trebuie sÄƒ copieze `postgresql.production.conf` pe producÈ›ie Ã®n loc de `postgresql.conf`
2. FiÈ™ierul `postgresql.production.conf` are setÄƒri corecte pentru 10GB RAM, dar are un bug: `port = 5432` trebuie schimbat la `port = 64032`
3. Nu mÄƒri `shared_buffers` sau `work_mem` peste valorile din fiÈ™ierul production; serverul gÄƒzduieÈ™te È™i IWMS/WMS/WAppBuss.

```bash
# Fix Ã®n repo:
# infra/config/postgres/postgresql.production.conf linia 4:
# SCHIMBÄ‚: port = 5432
# CU:      port = 64032
```

**FiÈ™iere de actualizat:**
- `infra/config/postgres/postgresql.production.conf` â€” fix port 5432 â†’ 64032
- `.github/workflows/deploy.yml` â€” secÈ›iunea de config sync production trebuie sÄƒ copieze `postgresql.production.conf` ca `postgresql.conf`

**Implementare exclusiv prin CI/CD (push Ã®n main):**
- Schimbarea fiÈ™ierului È™i sincronizarea pe producÈ›ie se fac doar prin deploy automat (push Ã®n `main`).
- Nu copia manual fiÈ™iere pe producÈ›ie; foloseÈ™te doar pasul de sync din pipeline.

---

### C4. docker-compose.prod.yml NU este aplicat pe producÈ›ie

**Severitate:** ğŸ”´ CRITICÄ‚  
**Server:** 95.216.225.145 (producÈ›ie)  
**Problema:** Containerele ruleazÄƒ doar cu `docker-compose.yml` (fÄƒrÄƒ override-ul prod). Asta Ã®nseamnÄƒ:
- PostgreSQL are limita 16GB memory pe server cu 10GB RAM
- Redis are maxmemory 8GB â€” combinat cu PG depÄƒÈ™eÈ™te RAM-ul fizic
- Swap usage deja la 48.7%

**Descoperire:**
```bash
docker inspect cerniq-postgres --format '{{json .Config.Labels}}' | jq '.["com.docker.compose.project.config_files"]'
# Output: "/opt/cerniq/docker-compose.yml"
# LIPSÄ‚: docker-compose.prod.yml
```

**Rezolvare (adaptat producÈ›ie cu RAM limitat):**
**Implementare:** Exclusiv prin CI/CD (push Ã®n `main`). Nu se ruleazÄƒ manual pe producÈ›ie.
```bash
# Rulat automat prin CI/CD pe runner-ul de producÈ›ie
cd /opt/cerniq
docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d --force-recreate
```

**NotÄƒ:** VerificÄƒ dupÄƒ recreare cÄƒ `Memory` limits nu depÄƒÈ™esc 10GB total. Scop: PG 4G, Redis 1-2G, restul sub 1G.

**Implementare exclusiv prin CI/CD (push Ã®n main):**
- Deploy-ul trebuie sÄƒ ruleze `docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d --force-recreate` din pipeline.
- Nu rula manual `docker compose` pe producÈ›ie; ruleazÄƒ doar prin workflow-ul de deploy la push Ã®n `main`.

**FiÈ™iere de actualizat:**
- `.github/workflows/deploy.yml` â€” verificÄƒ cÄƒ deploy production foloseÈ™te `-f docker-compose.yml -f docker-compose.prod.yml`

---

### C5. Backup-uri NE-programate pe producÈ›ie

**Severitate:** ğŸ”´ CRITICÄ‚  
**Server:** 95.216.225.145 (producÈ›ie)  
**Problema:** Scripturile de backup existÄƒ Ã®n `/opt/cerniq/scripts/` dar **nu sunt Ã®n crontab**. Zero backup-uri automate active. Log-ul de backup e gol.

**Descoperire:**
```bash
crontab -l | grep -i backup
# NIMIC

cat /var/log/borg_backup.log
# EMPTY
```

**Rezolvare (adaptat producÈ›ie cu disk 76% utilizat):**
**Implementare:** Exclusiv prin CI/CD (push Ã®n `main`). Nu se ruleazÄƒ manual pe producÈ›ie.
```bash
# Rulat automat prin CI/CD pe runner-ul de producÈ›ie
cp /opt/cerniq/config/cron/cerniq-backup /etc/cron.d/cerniq-backup
chmod 644 /etc/cron.d/cerniq-backup
chown root:root /etc/cron.d/cerniq-backup
systemctl restart cron

# Verificare:
crontab -l
```

**NotÄƒ:** Ãnainte de a porni Borg full backup, elibereazÄƒ spaÈ›iu (È™terge cache Docker + arhiveazÄƒ aplicaÈ›ii legacy) pentru a evita umplerea discului.

**Implementare exclusiv prin CI/CD (push Ã®n main):**
- AdaugÄƒ Ã®n `.github/workflows/deploy.yml` step de copiere a cron-ului Ã®n `/etc/cron.d/` È™i restart cron.
- Nu edita crontab manual pe producÈ›ie; foloseÈ™te doar deploy-ul automat la push Ã®n `main`.

ConÈ›inutul cron-ului (din `infra/config/cron/cerniq-backup`):
```
# Zilnic 04:00 â€” Borg backup complet
0 4 * * * root /opt/cerniq/scripts/borg_backup_daily.sh

# Duminici 05:00 â€” Borg check integritate
0 5 * * 0 root /opt/cerniq/scripts/borg_check.sh

# Orar â€” Redis backup
0 * * * * root /opt/cerniq/scripts/redis_backup_hourly.sh

# Zilnic 03:30 â€” pg_dump
30 3 * * * root /opt/cerniq/scripts/pg_dump_daily.sh

# Lunar, ziua 1, 07:00 â€” Restore test
0 7 1 * * root /opt/cerniq/scripts/backup_restore_test.sh
```

**FiÈ™iere de actualizat:**
- `.github/workflows/deploy.yml` â€” secÈ›iunea deploy production trebuie sÄƒ copieze cron-ul la `/etc/cron.d/`

---

### C6. Port mismatch pe producÈ›ie (compose zice 64032, containere ascultÄƒ pe 5432)

**Severitate:** ğŸ”´ CRITICÄ‚  
**Server:** 95.216.225.145 (producÈ›ie)  
**Problema:** Docker-compose.yml actualizat la port 64032 dar containerele active folosesc portul 5432 (din versiunea anterioarÄƒ). Un `docker compose up -d` va sparge conectivitatea DB.

**Descoperire:**
```
# Ãn compose (actualizat):
LISTEN_PORT: 64033        # PgBouncer
port = 64032              # PostgreSQL

# Containere active (vechi):
pg_isready -p 5432        # healthcheck ruleazÄƒ pe 5432
DB_PORT: 5432             # PgBouncer conectare la PG
```

**Rezolvare (adaptat producÈ›ie + risc minim):**
**Implementare:** Exclusiv prin CI/CD (push Ã®n `main`). Nu se ruleazÄƒ manual pe producÈ›ie.
Trebuie recreat cu atenÈ›ie â€” nu poÈ›i face direct `up -d` pentru cÄƒ va sparge tot:

```bash
# Rulat automat prin CI/CD pe runner-ul de producÈ›ie
cd /opt/cerniq

# 1. Backup date Ã®nainte de orice
docker exec cerniq-postgres pg_dump -U c3rn1q -d cerniq -F c -f /tmp/backup_before_port_change.dump

# 2. postgresql.production.conf trebuie port = 64032 (fix C3)

# 3. Stop, recreate ALL cu override-ul prod
docker compose -f docker-compose.yml -f docker-compose.prod.yml down
docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d

# 4. Verificare
docker exec cerniq-postgres pg_isready -h localhost -p 64032 -U c3rn1q
```

**NotÄƒ:** Fereastra de downtime trebuie coordonatÄƒ cu echipele IWMS/WAppBuss (server comun). RuleazÄƒ noaptea/local low-traffic.

**Implementare exclusiv prin CI/CD (push Ã®n main):**
- OperaÈ›iunea combinatÄƒ C3+C4+C6 se face doar prin pipeline-ul de production (push Ã®n `main`).
- Workflow-ul trebuie sÄƒ includÄƒ backup pre-recreate È™i recreate complet; nu rula manual pe producÈ›ie.

âš ï¸ **IMPORTANT:** C3, C4 È™i C6 trebuie rezolvate ÃMPREUNÄ‚ Ã®ntr-o singurÄƒ operaÈ›iune de recreare.

---

## 2. CRITICE â€” STAGING

### C7. Containere pornite din directoare diferite (split working directory)

**Severitate:** ğŸŸ  HIGH  
**Server:** Staging 135.181.183.164  
**Problema:** Postgres + PgBouncer ruleazÄƒ din `/opt/cerniq` (prod override), dar celelalte 6 containere ruleazÄƒ din `/var/www/CerniqAPP/infra/docker` (repo direct). Asta Ã®nseamnÄƒ cÄƒ 6 containere NU folosesc docker-compose.prod.yml.

**Descoperire:**
```
cerniq-postgres    â†’ WorkingDir: /opt/cerniq (CORECT)
cerniq-pgbouncer   â†’ WorkingDir: /opt/cerniq (CORECT)
cerniq-redis       â†’ WorkingDir: /var/www/CerniqAPP/infra/docker (GREÈ˜IT)
cerniq-traefik     â†’ WorkingDir: /var/www/CerniqAPP/infra/docker (GREÈ˜IT)
cerniq-openbao     â†’ WorkingDir: /var/www/CerniqAPP/infra/docker (GREÈ˜IT)
... (Ã®ncÄƒ 3)
```

**Rezolvare (adaptat staging cu alte proiecte active):**
```bash
cd /opt/cerniq
docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d --force-recreate
```

**NotÄƒ:** VerificÄƒ Ã®nainte cÄƒ porturile 80/443 rÄƒmÃ¢n gestionate de `neanelu_traefik` È™i cÄƒ Nginx proxy (64443) rÄƒmÃ¢ne neschimbat.

Toate containerele trebuie pornite din `/opt/cerniq` cu ambele compose files.

---

### C8. Traefik config LIPSÄ‚ din /opt/cerniq/config/traefik/

**Severitate:** ğŸŸ  HIGH  
**Server:** Staging 135.181.183.164  
**Problema:** Directorul `/opt/cerniq/config/traefik/` nu conÈ›ine `traefik.yml` È™i `dynamic/middlewares.yml`. Traefik funcÈ›ioneazÄƒ doar pentru cÄƒ a fost pornit din repo. DacÄƒ se reporneÈ™te din `/opt/cerniq`, va eÈ™ua.

**Rezolvare (adaptat staging cu Neanelu Traefik activ):**
```bash
# Copiere config traefik la locaÈ›ia corectÄƒ
mkdir -p /opt/cerniq/config/traefik/dynamic
cp /var/www/CerniqAPP/infra/docker/traefik/traefik.yml /opt/cerniq/config/traefik/
cp /var/www/CerniqAPP/infra/docker/traefik/dynamic/middlewares.yml /opt/cerniq/config/traefik/dynamic/
```

**NotÄƒ:** Nu modifica `neanelu_traefik` È™i nu schimba binding-ul 80/443. Cerniq Traefik rÄƒmÃ¢ne doar pe 64080.

**FiÈ™iere de actualizat:**
- `.github/workflows/deploy.yml` â€” secÈ›iunea staging config sync trebuie sÄƒ copieze È™i traefik configs
- `infra/docker/docker-compose.prod.yml` â€” verificÄƒ mount-urile traefik sÄƒ pointeze la `./config/traefik/`

---

### C9. OpenBao templates pe staging au port PgBouncer GREÈ˜IT

**Severitate:** ğŸŸ  HIGH  
**Server:** Staging 135.181.183.164  
**Problema:** Template-urile OpenBao deployed conÈ›in `pgbouncer:6432` dar PgBouncer ascultÄƒ pe `64033`. CÃ¢nd API/workers vor porni, vor primi un DATABASE_URL greÈ™it.

**Descoperire:**
```
# Pe staging deployed:
DATABASE_URL=postgresql://...@pgbouncer:6432/cerniq

# Ãn repo (corect):
DATABASE_URL=postgresql://...@pgbouncer:64033/cerniq
```

**Rezolvare (adaptat staging):**
```bash
# Resync templates din repo
cp /var/www/CerniqAPP/infra/config/openbao/templates/api-env.tpl /opt/cerniq/config/openbao/templates/
cp /var/www/CerniqAPP/infra/config/openbao/templates/workers-env.tpl /opt/cerniq/config/openbao/templates/

# Restart agents
cd /opt/cerniq
docker compose -f docker-compose.yml -f docker-compose.prod.yml restart openbao-agent-api openbao-agent-workers
```

**NotÄƒ:** Nu reporni alte proiecte (Neanelu/GeniusSuite/TLC4Pipes). LimiteazÄƒ restartul strict la agenti OpenBao.

---

## 3. CRITICE â€” REPO/CI/CD

### C10. Trivy image scan NU blocant Ã®n deploy.yml

**Severitate:** ğŸŸ  HIGH  
**FiÈ™ier:** `.github/workflows/deploy.yml`  
**Problema:** Scanarea Trivy a imaginilor Docker Ã®n pipeline-ul de deploy are `exit-code: '0'` È™i `continue-on-error: true`. VulnerabilitÄƒÈ›ile HIGH/CRITICAL nu blocheazÄƒ deploy-ul.

**Descoperire:**
```yaml
# deploy.yml linia ~200:
- name: Security scan
  run: |
    trivy image ... --exit-code 0 --severity HIGH,CRITICAL
  continue-on-error: true
```

**Rezolvare:**
```yaml
# SchimbÄƒ exit-code la 1 È™i eliminÄƒ continue-on-error:
- name: Security scan
  run: |
    trivy image ... --exit-code 1 --severity HIGH,CRITICAL
```

**NotÄƒ (impact mediu):** RuleazÄƒ doar Ã®n CI. Self-hosted runner-ul este pe staging; evitÄƒ ferestrele de load ridicat pentru a nu afecta celelalte proiecte de pe aceeaÈ™i maÈ™inÄƒ.

**FiÈ™iere de actualizat:**
- `.github/workflows/deploy.yml` â€” Trivy exit-code 0 â†’ 1, eliminÄƒ continue-on-error

---

### C11. Plaintext password Ã®n infra/docker/.env

**Severitate:** ğŸŸ  HIGH  
**FiÈ™ier:** `infra/docker/.env`  
**Problema:** ConÈ›ine `POSTGRES_PASSWORD=ZxyHcMlDTjiA4Nv46RYMS2MTcx5lXayJfrC02EEI6WwYZ2uwERrTYnix81221vc` Ã®n clar. DeÈ™i `.env` e gitignored È™i variabila nu e folositÄƒ (compose foloseÈ™te `POSTGRES_PASSWORD_FILE`), e o parolÄƒ rezidualÄƒ pe disc.

**Rezolvare:**
```bash
# EliminÄƒ linia cu POSTGRES_PASSWORD din .env sau È™terge fiÈ™ierul dacÄƒ nu are alt conÈ›inut util
sed -i '/POSTGRES_PASSWORD/d' /var/www/CerniqAPP/infra/docker/.env
```

**NotÄƒ (impact mediu):** Modificare doar Ã®n repo. Nu È™terge alte fiÈ™iere `.env` din proiectele coexistente (Neanelu/GeniusSuite/TLC4Pipes).

---

### C12. validate-postgres.sh: DB_USER greÈ™it

**Severitate:** ğŸŸ  HIGH  
**FiÈ™ier:** `infra/scripts/validate-postgres.sh`, linia 12  
**Problema:** `DB_USER="cerniq"` cÃ¢nd user-ul corect este `c3rn1q`. Scriptul va eÈ™ua la conectare.

**Rezolvare:**
```bash
# validate-postgres.sh linia 12:
# SCHIMBÄ‚: DB_USER="cerniq"
# CU:      DB_USER="c3rn1q"
```

**NotÄƒ (impact mediu):** FoloseÈ™te scriptul doar Ã®n CI sau staging; nu rula validÄƒri agresive pe producÈ›ie Ã®n ore de vÃ¢rf (server comun).

**FiÈ™iere de actualizat:**
- `infra/scripts/validate-postgres.sh` â€” linia 12: `DB_USER="c3rn1q"`

---

### C13. init.sql: password hardcodat pentru cerniq_vault

**Severitate:** ğŸŸ¡ MEDIUM  
**FiÈ™ier:** `infra/config/postgres/init.sql`, linia ~73  
**Problema:** `CREATE ROLE cerniq_vault WITH LOGIN PASSWORD 'vault_initial_password_change_me'` â€” parolÄƒ hardcodatÄƒ Ã®ntr-un fiÈ™ier committat.

**Rezolvare:**
Acceptabil ca password iniÈ›ial dacÄƒ este schimbat de OpenBao la prima configurare. AdaugÄƒ comentariu explicit:
```sql
-- IMPORTANT: AceastÄƒ parolÄƒ iniÈ›ialÄƒ este rotitÄƒ automat de OpenBao Database Engine
-- la prima execuÈ›ie a openbao-setup-database.sh. NU folosiÈ›i manual.
CREATE ROLE cerniq_vault WITH LOGIN PASSWORD 'vault_initial_password_change_me';
```

**NotÄƒ (impact mediu):** Doar documentare Ã®n repo. Nu reporni Postgres pe producÈ›ie doar pentru acest comentariu.

---

## 4. DOCUMENTAÈšIE â€” ADR-uri stale

### D1. ADR-0015: Subnete greÈ™ite

**FiÈ™ier:** `docs/adr/ADR Etapa 0/ADR-0015-Docker-Containerization-Strategy.md`  
**Problema:** DocumenteazÄƒ subnete `172.20.0.0/24`, `172.21.0.0/24`, `172.22.0.0/24` dar implementarea foloseÈ™te `172.29.10.0/24`, `172.29.20.0/24`, `172.29.30.0/24`.

**Rezolvare:** ActualizeazÄƒ ADR-0015 cu subnet-urile reale:
- `cerniq_public` â€” `172.29.10.0/24`
- `cerniq_backend` â€” `172.29.20.0/24`  
- `cerniq_data` â€” `172.29.30.0/24`

**NotÄƒ (impact mediu):** MenÈ›ioneazÄƒ explicit cÄƒ **producÈ›ia** foloseÈ™te 172.27/28/29.0.0/24, iar staging 172.29.10/20/30.0/24. DocumentaÈ›ia NU trebuie interpretatÄƒ ca instrucÈ›iune de schimbare a reÈ›elelor live.

---

### D2. ADR-0022: Port PgBouncer greÈ™it

**FiÈ™ier:** `docs/adr/ADR Etapa 0/ADR-0022-*.md`  
**Problema:** DocumenteazÄƒ PgBouncer pe portul `64042` dar implementarea foloseÈ™te `64033`.

**Rezolvare:** ActualizeazÄƒ portul PgBouncer la `64033` Ã®n ADR-0022.

**NotÄƒ (impact mediu):** Update doar Ã®n documentaÈ›ie. Nu schimba porturile runtime pe celelalte proiecte.

---

### D3. ADR-0004: max_connections È™i io_method

**FiÈ™ier:** `docs/adr/ADR Etapa 0/ADR-0004-*.md`  
**Problema:**
- ADR specificÄƒ `max_connections = 200` dar postgresql.conf are `100`
- ADR specificÄƒ `io_method = io_uring` dar implementarea foloseÈ™te `worker` (limitare Docker)

**Rezolvare:** AdaugÄƒ note in ADR-0004:
- Staging: `max_connections = 100` (suficient pentru load actual)
- `io_method = worker` din cauza lipsei suport `io_uring` Ã®n containerele Docker
- ProducÈ›ie: `max_connections = 50` (server mic, 4 cores)

**NotÄƒ (impact mediu):** ClarificÄƒ cÄƒ setÄƒrile diferÄƒ Ã®ntre staging È™i producÈ›ie din cauza resurselor limitate È™i a coexistenÈ›ei altor proiecte pe producÈ›ie.

---

### D4. Port Matrix: subnete È™i port-uri greÈ™ite

**FiÈ™ier:** `docs/specifications/Etapa 0/etapa0-port-matrix.md`  
**Problema:**
- SecÈ›iunea Docker Network Configuration aratÄƒ subnete 172.20/21/22 Ã®n loc de 172.29.10/20/30
- SigNoz listat pe port 64080 (conflict cu Traefik)
- PgBouncer (64033) nu e Ã®n tabel
- OpenBao (64090) nu e explicit Ã®n tabelul Service-to-Port Mapping

**Rezolvare:** ActualizeazÄƒ port-matrix cu valorile reale din docker-compose.yml.

**NotÄƒ (impact mediu):** Include porturile celorlalte proiecte pe producÈ›ie (3000/3002, 3060-3063, 5173) ca â€reserved/externalâ€ ca sÄƒ evitÄƒm coliziuni viitoare.

---

### D5. Versiune Traefik â€” comentarii stale

**FiÈ™iere:**
- `infra/docker/traefik/traefik.yml` â€” header zice `v3.3.5`
- `infra/scripts/trivy-scan.sh` â€” referÄƒ `traefik:v3.3.3`

**Problema:** Versiunea realÄƒ e `traefik:v3.6` (din docker-compose.yml). Comentariile sunt vechi.

**Rezolvare:** ActualizeazÄƒ versiunea la `v3.6` (sau `v3.6.7` â€” versiunea exactÄƒ care ruleazÄƒ) Ã®n:
- `infra/docker/traefik/traefik.yml` header
- `infra/scripts/trivy-scan.sh` lista de imagini

**NotÄƒ (impact mediu):** Doar actualizare de comentarii È™i scan list. Nu schimbÄƒ imaginile runtime pÃ¢nÄƒ nu existÄƒ fereastrÄƒ de mentenanÈ›Äƒ.

---

### D6. openbao.hcl: typo port

**FiÈ™ier:** `infra/config/openbao/openbao.hcl`  
**Problema:** Comentariu zice "exposed as 64200" dar portul real e `64090`.

**Rezolvare:** Fix comentariu: `# Port 8200 internal - exposed as 64090 on localhost only via Docker`

**NotÄƒ (impact mediu):** Nu necesitÄƒ redeploy sau restart.

---

## 5. CI/CD â€” Gapuri pipeline

### CI1. Security scans ruleazÄƒ doar pe PRs la develop

**FiÈ™ier:** `.github/workflows/ci-pr.yml`  
**Problema:** Job-ul `security` (Trivy + pnpm audit) se executÄƒ doar pe `pull_request` cu `base_ref == 'develop'`. PRs la `main` NU au scanare de securitate.

**Rezolvare:**
```yaml
# SchimbÄƒ condiÈ›ia:
if: github.event_name == 'pull_request'
# Ãn loc de:
if: github.event_name == 'pull_request' && github.base_ref == 'develop'
```

**NotÄƒ (impact mediu):** RulÄƒrile au loc pe runner-ul staging; programeazÄƒ scanÄƒrile grele (Trivy) Ã®n afara orelor de vÃ¢rf ale celorlalte proiecte.

---

### CI2. Production smoke test failures NU blocheazÄƒ deploy

**FiÈ™ier:** `.github/workflows/deploy.yml`  
**Problema:** Ãn secÈ›iunea smoke tests producÈ›ie, `exit 1` este comentat. DacÄƒ un smoke test eÈ™ueazÄƒ, deploy-ul continuÄƒ.

**Rezolvare:** De-comentat `exit 1` Ã®n smoke tests producÈ›ie. EÈ™ecurile trebuie sÄƒ opreascÄƒ pipeline-ul.

**NotÄƒ (impact mediu):** Smoke tests trebuie sÄƒ fie read-only È™i sÄƒ nu atingÄƒ aplicaÈ›iile non-Cerniq de pe producÈ›ie (IWMS/WAppBuss).
**Implementare:** Exclusiv prin CI/CD (push Ã®n `main`). Nu se ruleazÄƒ manual pe producÈ›ie.

---

### CI3. Workers lipsesc din deploy.yml v2.0 build matrix

**FiÈ™ier:** `.github/workflows/deploy.yml`  
**Problema:** Versiunea v2.0 construieÈ™te doar 3 imagini (api, web, web-admin). Worker images (worker-ai, worker-enrichment, worker-outreach) au fost eliminate.

**Rezolvare:** AdaugÄƒ workers Ã®napoi Ã®n build matrix sau documenteazÄƒ decizia de excludere explicitÄƒ (dacÄƒ workers nu se deploy-eazÄƒ ca containere Docker separate).

**NotÄƒ (impact mediu):** DacÄƒ workers sunt adÄƒugaÈ›i, verificÄƒ resursele pe producÈ›ie (10GB RAM) È™i evitÄƒ lansarea lor Ã®nainte de a ajusta limits.
**Implementare:** Exclusiv prin CI/CD (push Ã®n `main`) pentru orice schimbare care afecteazÄƒ deploy-ul pe producÈ›ie.

---

### CI4. Prettier check lipsÄƒ din CI

**FiÈ™ier:** `.github/workflows/ci-pr.yml`  
**Problema:** ESLint ruleazÄƒ dar Prettier nu. Nu se verificÄƒ formatarea codului.

**Rezolvare:** AdaugÄƒ step `pnpm format:check` Ã®n job-ul `lint`, sau integreazÄƒ Prettier Ã®n ESLint config.

**NotÄƒ (impact mediu):** RuleazÄƒ doar Ã®n CI; nu e nevoie sÄƒ rulezi pe servere.

---

### CI5. ShellCheck lipsÄƒ

**FiÈ™ier:** `.github/workflows/ci-pr.yml`  
**Problema:** Scripturile bash sunt validate doar cu `bash -n` (syntax check). ShellCheck (best practices, bugs potenÈ›iale) nu ruleazÄƒ.

**Rezolvare:**
```yaml
- name: ShellCheck
  run: |
    apt-get install -y shellcheck
    find infra/scripts -name '*.sh' -exec shellcheck {} +
```

**NotÄƒ (impact mediu):** FoloseÈ™te caching Ã®n CI dacÄƒ e posibil; staging runner are È™i alte proiecte.

---

### CI6. dependabot.yml / Renovate lipsÄƒ

**FiÈ™ier:** `.github/dependabot.yml`  
**Problema:** Nu existÄƒ mecanism automat de actualizare dependenÈ›e.

**Rezolvare:** CreeazÄƒ `.github/dependabot.yml`:
```yaml
version: 2
updates:
  - package-ecosystem: "npm"
    directory: "/"
    schedule:
      interval: "weekly"
  - package-ecosystem: "docker"
    directory: "/infra/docker"
    schedule:
      interval: "weekly"
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"
```

**NotÄƒ (impact mediu):** Dependabot doar propune PR-uri; nu afectaÈ›i serverele fÄƒrÄƒ aprobÄƒri È™i ferestre dedicate.

---

### CI7. Test results JSON nu sunt uploadate ca artifacts

**FiÈ™ier:** `.github/workflows/ci-pr.yml`  
**Problema:** Coverage merge la Codecov dar rezultatele testelor (vitest-results.json) nu sunt salvate ca GitHub artifacts. Imposibil de urmÄƒrit trenduri.

**Rezolvare:**
```yaml
- name: Upload test results
  if: always()
  uses: actions/upload-artifact@v4
  with:
    name: test-results
    path: test-results/
    retention-days: 30
```

**NotÄƒ (impact mediu):** Upload doar din CI. Nu copia rezultate pe producÈ›ie.

---

## 6. TESTE â€” Gapuri infrastructurÄƒ

### T1. Zero unit tests

**Director:** `tests/unit/`  
**Problema:** Directorul e GOL. Master plan-ul cere ~2000+ unit tests (70% din piramida de testare).

**Rezolvare:** Unit tests vor fi create pe mÄƒsurÄƒ ce se implementeazÄƒ business logic (Etapele 1+). Pentru Etapa 0 (infrastructurÄƒ), E2E tests sunt suficiente. DocumenteazÄƒ decizia.

**NotÄƒ (impact mediu):** Nu rula suite de teste pe producÈ›ie; foloseÈ™te CI È™i staging.

---

### T2. Zero integration tests

**Director:** `tests/integration/`  
**Problema:** Directorul e GOL.

**Rezolvare:** La fel ca T1 â€” integration tests apar cu cod de aplicaÈ›ie. Etapa 0 testeazÄƒ infrastructura prin E2E.

**NotÄƒ (impact mediu):** Integrarea va fi testatÄƒ pe staging, nu pe producÈ›ie, pentru a nu afecta celelalte proiecte.

---

### T3. Rezultate test stale (doar 2/7 fiÈ™iere)

**FiÈ™ier:** `test-results/vitest-results.json`  
**Problema:** ConÈ›ine rezultate doar din 2 fiÈ™iere de test (131 assertions). Celelalte 5 fiÈ™iere au fost adÄƒugate ulterior.

**Rezolvare:**
```bash
pnpm test:ci
# RegenereazÄƒ test-results/vitest-results.json cu toate cele 7 fiÈ™iere
```

**NotÄƒ (impact mediu):** RuleazÄƒ local sau Ã®n CI; nu executa pe serverul de producÈ›ie.

---

### T4. Coverage niciodatÄƒ generatÄƒ local

**Director:** `./coverage/` â€” nu existÄƒ  
**Problema:** `pnpm test:coverage` nu a fost rulat niciodatÄƒ local.

**Rezolvare:**
```bash
pnpm test:coverage
# GenereazÄƒ ./coverage/ cu raport HTML È™i JSON
```

**NotÄƒ (impact mediu):** RuleazÄƒ local/CI; nu pe staging Ã®n timpul traficului altor proiecte.

---

### T5. Package-uri workspace fÄƒrÄƒ package.json

**Directoare:** `apps/api/`, `apps/web/`, `packages/db/`, etc.  
**Problema:** Niciun sub-package din monorepo nu are propriul `package.json`. pnpm workspace globs (`apps/*`, `packages/*`, `workers/*`) nu rezolvÄƒ nimic.

**Rezolvare:** Fiecare package trebuie sÄƒ aibÄƒ cel puÈ›in:
```json
{
  "name": "@cerniq/api",
  "version": "0.0.1",
  "private": true
}
```

Aceasta e o sarcinÄƒ pentru Sprint 5-6 (F0.6 Monorepo Setup, F0.9 API Boilerplate).

**NotÄƒ (impact mediu):** Modificare strict Ã®n repo; nu afecteazÄƒ aplicaÈ›iile coexistente.

---

### T6. CI foloseÈ™te test:coverage dar test:ci e mai potrivit

**FiÈ™ier:** `.github/workflows/ci-pr.yml`  
**Problema:** CI ruleazÄƒ `pnpm test:coverage` dar `test:ci` genereazÄƒ È™i JSON output structured. Ar trebui combinat.

**Rezolvare:**
```json
{
  "test:ci": "vitest run --coverage --reporter=json --reporter=verbose --outputFile=test-results/results.json"
}
```

È˜i Ã®n CI:
```yaml
- run: pnpm test:ci
```

**NotÄƒ (impact mediu):** AsigurÄƒ cÄƒ runner-ul are suficiente resurse; evitÄƒ rulÄƒri concurente cu build-uri heavy pentru GeniusSuite/Neanelu pe aceeaÈ™i maÈ™inÄƒ.

---

## 7. SECURITATE â€” Staging & General

### S1. Docker metrics pe 0.0.0.0:64094

**FiÈ™ier:** `/etc/docker/daemon.json`  
**Server:** Staging  
**Problema:** `metrics-addr: "0.0.0.0:64094"` expune metrici Docker pe toate interfeÈ›ele. Docker bypass-eazÄƒ UFW via iptables.

**Rezolvare:**
```json
{
  "metrics-addr": "127.0.0.1:64094"
}
```

**FiÈ™iere de actualizat:**
- `infra/config/docker/daemon.json` (dacÄƒ existÄƒ Ã®n repo)
- Server: `/etc/docker/daemon.json` + `systemctl restart docker`

**NotÄƒ (impact mediu):** Restart-ul Docker afecteazÄƒ **toate** proiectele de pe staging (Neanelu, GeniusSuite, TLC4Pipes). ProgrameazÄƒ fereastrÄƒ de mentenanÈ›Äƒ È™i anunÈ›Äƒ echipele.

---

### S2. FiÈ™iere secrete cu permisiuni 0644 (world-readable)

**Server:** Staging (`/opt/cerniq/secrets/`)  
**Problema:** `postgres_password.txt`, `api_role_id`, etc. sunt readable de oricine (0644).

**Rezolvare:**
```bash
chmod 600 /opt/cerniq/secrets/*.txt
chmod 600 /opt/cerniq/secrets/*_id
chown root:root /opt/cerniq/secrets/*
```

**NotÄƒ (impact mediu):** AplicÄƒ doar Ã®n `/opt/cerniq/secrets/`, nu atinge secretele altor proiecte.

**FiÈ™iere de actualizat:**
- `.github/workflows/deploy.yml` â€” adaugÄƒ `chmod 600` pe secrets dupÄƒ sync

---

### S3. UFW permite ports 5000-5002 nefolosite pe staging

**Server:** Staging  
**Problema:** Reguli UFW pentru porturi care nu aparÈ›in Cerniq.

**Rezolvare:**
```bash
ufw delete allow 5000:5002/tcp
```

**NotÄƒ (impact mediu):** VerificÄƒ Ã®nainte cÄƒ niciun proiect local nu foloseÈ™te 5000-5002 (ex. Neanelu/GeniusSuite). DacÄƒ existÄƒ dependenÈ›e, pÄƒstreazÄƒ regulile È™i documenteazÄƒ.

---

### S4. PgBouncer: tag `latest` (trebuie pinned)

**FiÈ™ier:** `infra/docker/docker-compose.yml`  
**Problema:** `image: edoburu/pgbouncer:latest` â€” nu e reproducibil.

**Rezolvare:**
```yaml
image: edoburu/pgbouncer:1.25.1
```

**NotÄƒ (impact mediu):** Schimbarea imaginii se aplicÄƒ doar la recreate; evitÄƒ restarturi neplanificate pe servere comune.

---

### S5. staging-proxy fÄƒrÄƒ healthcheck

**FiÈ™ier:** `infra/docker/docker-compose.yml`  
**Problema:** Containerul `cerniq-staging-proxy` (nginx) nu are healthcheck definit.

**Rezolvare:**
```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:80/"]
  interval: 30s
  timeout: 5s
  retries: 3
```

**NotÄƒ (impact mediu):** Healthcheck-ul afecteazÄƒ doar containerul Cerniq; nu modifica proiectele coexistente.

---

### S6. Root token OpenBao pÄƒstrat pe disc

**FiÈ™ier:** `secrets/openbao_root_token.txt`  
**Problema:** Root token-ul ar trebui revocat dupÄƒ setup iniÈ›ial; AppRole se foloseÈ™te exclusiv.

**Rezolvare:** DupÄƒ ce toate serviciile funcÈ›ioneazÄƒ corect cu AppRole:
```bash
bao token revoke $(cat secrets/openbao_root_token.txt)
rm secrets/openbao_root_token.txt
```

âš ï¸ **AtenÈ›ie:** Acest lucru trebuie fÄƒcut DOAR dupÄƒ ce s-a confirmat cÄƒ AppRole auth funcÈ›ioneazÄƒ corect È™i backup-uri OpenBao sunt operaÈ›ionale (altfel pierzi acces permanent).

**NotÄƒ (impact mediu):** RuleazÄƒ doar dupÄƒ ce atÃ¢t staging cÃ¢t È™i producÈ›ia sunt stabile; altfel riÈ™ti sÄƒ blochezi recuperarea secretelor pe servere partajate.

---

### S7. Toate 5 unseal keys Ã®n acelaÈ™i fiÈ™ier pe acelaÈ™i server

**FiÈ™ier:** `secrets/openbao_unseal_keys.txt`  
**Problema:** Shamir secret sharing presupune distribuirea cheilor la persoane/locaÈ›ii diferite. Toate 5 pe acelaÈ™i server anuleazÄƒ beneficiul.

**Rezolvare (pe termen lung):**
- Cheia 1: pe staging server
- Cheia 2: pe producÈ›ie server  
- Cheia 3: Ã®n password manager (1Password/Bitwarden)
- Cheia 4: la team lead (offline)
- Cheia 5: backup encrypted pe Hetzner Storage Box

**Rezolvare (pe termen scurt â€” acceptabilÄƒ pentru Etapa 0):** DocumenteazÄƒ riscul È™i planul de distribuire.

**NotÄƒ (impact mediu):** DistribuÈ›ia cheilor trebuie coordonatÄƒ Ã®ntre echipele care administreazÄƒ È™i celelalte proiecte de pe server.

---

### S8. workers-env.tpl semnalizeazÄƒ `pkill -HUP python` dar workers sunt Node.js

**FiÈ™ier:** `infra/config/openbao/agent-workers.hcl`, linia ~63  
**Problema:** Template reload command trimite SIGHUP la Python, dar workers sunt Node.js/BullMQ.

**Rezolvare:**
```hcl
# SCHIMBÄ‚: command = "pkill -HUP python || true"
# CU:      command = "pkill -HUP node || true"
```

**NotÄƒ (impact mediu):** Modificare doar Ã®n repo; nu afecteazÄƒ alte proiecte. AplicÄƒ la urmÄƒtorul deploy planificat.

---

## 8. ORDINE IMPLEMENTARE

### Faza 1: CRITICE PRODUCÈšIE (imediat)

**Toate acÈ›iunile din Faza 1 se executÄƒ exclusiv prin CI/CD la push Ã®n `main`.**

| Pas | ProblemÄƒ | AcÈ›iune |
|-----|----------|---------|
| 1.1 | C1 | Activare UFW pe producÈ›ie (CI/CD) |
| 1.2 | C3 | Fix postgresql.production.conf port 5432â†’64032 (CI/CD) |
| 1.3 | C4+C6 | Recreare containere producÈ›ie cu `-f docker-compose.prod.yml` (CI/CD) |
| 1.4 | C2 | Configurare OpenBao engines+policies pe producÈ›ie (CI/CD) |
| 1.5 | C5 | Instalare cron backup-uri pe producÈ›ie (CI/CD) |

### Faza 2: CRITICE STAGING (dupÄƒ producÈ›ie)

| Pas | ProblemÄƒ | AcÈ›iune |
|-----|----------|---------|
| 2.1 | C8 | Copiere config traefik la /opt/cerniq/config/traefik/ |
| 2.2 | C9 | Resync OpenBao templates (port pgbouncer) |
| 2.3 | C7 | Recreare toate containerele din /opt/cerniq |

### Faza 3: REPO FIXES (dupÄƒ servere stabile)

| Pas | ProblemÄƒ | AcÈ›iune |
|-----|----------|---------|
| 3.1 | C10 | Trivy exit-code 0â†’1 Ã®n deploy.yml (CI/CD) |
| 3.2 | C12 | validate-postgres.sh DB_USER fix (CI/CD) |
| 3.3 | C11 | Eliminare password din .env (CI/CD) |
| 3.4 | S4 | Pin PgBouncer version (CI/CD) |
| 3.5 | S5 | Healthcheck staging-proxy (CI/CD) |
| 3.6 | S8 | Fix pkill pythonâ†’node (CI/CD) |
| 3.7 | D6 | Fix openbao.hcl typo port (CI/CD) |

### Faza 4: CI/CD IMPROVEMENTS

| Pas | ProblemÄƒ | AcÈ›iune |
|-----|----------|---------|
| 4.1 | CI1 | Extinde security scans la PRs main (CI/CD) |
| 4.2 | CI2 | Decomentare exit 1 smoke tests producÈ›ie (CI/CD) |
| 4.3 | CI7 | Upload test artifacts (CI/CD) |
| 4.4 | CI4 | Prettier check (CI/CD) |
| 4.5 | CI5 | ShellCheck (CI/CD) |
| 4.6 | CI6 | dependabot.yml (CI/CD) |
| 4.7 | T6 | Combinare test:ci cu coverage (CI/CD) |

### Faza 5: DOCUMENTAÈšIE

| Pas | ProblemÄƒ | AcÈ›iune |
|-----|----------|---------|
| 5.1 | D1 | ADR-0015 subnete |
| 5.2 | D2 | ADR-0022 port PgBouncer |
| 5.3 | D3 | ADR-0004 max_connections + io_method |
| 5.4 | D4 | Port matrix |
| 5.5 | D5 | Versiune Traefik |

### Faza 6: SECURITATE (low-urgency)

| Pas | ProblemÄƒ | AcÈ›iune |
|-----|----------|---------|
| 6.1 | S1 | daemon.json metrics binding |
| 6.2 | S2 | Permisiuni secrete 600 |
| 6.3 | S3 | UFW ports 5000-5002 |
| 6.4 | S6 | Plan revocare root token |
| 6.5 | S7 | Plan distribuire unseal keys |
| 6.6 | C13 | Documentare password init vault |

---

**TOTAL:** 13 probleme critice, 7 documentaÈ›ii stale, 7 gapuri CI/CD, 6 gapuri teste, 8 probleme securitate  
**ESTIMARE:** ~2-3 zile implementare completÄƒ (Faza 1 urgentÄƒ = cÃ¢teva ore)
